{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model for Occupancy Prediction in an Office Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Analytics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "## Plots\n",
    "\n",
    "# Import matplotlib and seaborn for plotting and use magic command for Jupyter Notebooks\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Set the style for plots\n",
    "plt.style.use('fivethirtyeight')\n",
    "#plt.rc(\"font\", size=14)\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='whitegrid', font='Arial', rc={'figure.figsize':(10,5),\n",
    "            'font.size':14,\n",
    "            'axes.titlesize':16,\n",
    "            'axes.labelsize':15,\n",
    "            'xtick.labelsize': 12,\n",
    "            'ytick.labelsize': 12,\n",
    "            'legend.fontsize': 13},color_codes=True)\n",
    "#sns.set(style=\"white\")\n",
    "#sns.set(style=\"whitegrid\", color_codes=True)\n",
    "#sns.set(rc={'figure.figsize':(20, 10)})\n",
    "# Pydot is used for visualization\n",
    "import pydot\n",
    "\n",
    "\n",
    "## Machine Learning\n",
    "\n",
    "# Skicit-learn\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "# Import the model that is used - Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "# Import function to calculate accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "# Precision and recall\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "# Import autocorrelation function\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "# Import Matthews Correlation Coefficient\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "\n",
    "# CSV\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 1\n",
    "def predict_with_model(fitted_model, X_val, y_val, output=True):\n",
    "    '''\n",
    "    Function to make a prediction based on a trained model, returns metrics for classification\n",
    "    \n",
    "    Inputs: \n",
    "    fitted_model: On a training set fitted model to use for prediction \n",
    "    X_val (np.array): numpy array with feature vectors of validation (or test) data\n",
    "    y_val (np.array): numpy array with true labels of validation(or test) data\n",
    "    output (bool): if output should be printed or not, default is True\n",
    "   \n",
    "    Outputs:\n",
    "    y_pred (np.array): Prediction for feature vectors of validation (or test) data of the model\n",
    "    metrics_dict (dict): Dictionary with metrics for classification\n",
    "    accuracy (float): Accuracy of the prediction\n",
    "    precision (float): Precision of the prediction\n",
    "    recall (float): Recall of the prediction\n",
    "    f1 (float): F1-Score of the prediction\n",
    "    mcc (float): Matthews Correlation Coefficient of the prediction\n",
    "    '''  \n",
    "    \n",
    "    # Use the trained model to make predictions on the validation (or test) set\n",
    "    y_pred = fitted_model.predict(X_val)\n",
    "    \n",
    "    ## Metrics for classification\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    # Precision\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    # Recall\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    # F1-Score\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    # MCC\n",
    "    mcc = matthews_corrcoef(y_val, y_pred)\n",
    "    \n",
    "        \n",
    "    metrics_dict = {'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1,\n",
    "                    'mcc': mcc\n",
    "                   }\n",
    "    \n",
    "    if output:\n",
    "        print('Mean of true labels:', round(np.mean(y_val), 2))\n",
    "        print('Accuracy:', accuracy)\n",
    "        print('Precision:', precision)\n",
    "        print('Recall:', recall)\n",
    "        print('F1-Score:', f1)\n",
    "        print('MCC:', mcc)\n",
    "            \n",
    "    return y_pred, metrics_dict, accuracy, precision, recall, f1, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 6\n",
    "def calculate_feature_importances(model, features, output=True):\n",
    "    '''\n",
    "    Function to calculate feature importances of a random forest model\n",
    "    \n",
    "    Inputs:\n",
    "    model: on a training set fitted and on a test set tested model\n",
    "    features (lst): list containing the names of the features\n",
    "    output: print results True or False (True by default)\n",
    "    \n",
    "    Outputs:\n",
    "    importances (lst): list with all importances for the features but not sorted (same order as features in input)\n",
    "    df_feature_importances (df): Dataframe with features and their corresponding importance sorted from highest to lowest\n",
    "    '''\n",
    "    # Get numerical feature importances\n",
    "    importances = list(model.feature_importances_)\n",
    "    \n",
    "    # List of tuples with feature and importance\n",
    "    feature_importances = [(feature, round(importance, 3)) for feature, importance in zip(feature_names, importances)]\n",
    "    \n",
    "    # Sort the feature importances from highest to lowest\n",
    "    feature_importances = sorted(feature_importances, key = lambda x:\n",
    "                                x[1], reverse = True)\n",
    "    \n",
    "    if output:\n",
    "        # Print out the feature and importances\n",
    "        [print('Feature: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]\n",
    "        \n",
    "    #df_feature_importances = pd.DataFrame(feature_importances, columns=['feature', 'importance'])\n",
    "    \n",
    "    return importances, feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 7\n",
    "def plot_roc(model, X_test, y_test):\n",
    "    '''\n",
    "    Function to plot Receiver Operating Curve in desired layout\n",
    "    \n",
    "    Inputs:\n",
    "    model: on a training set fitted and on a test set tested model\n",
    "    X_test (np.array): numpy array with feature vectors of test data\n",
    "    y_test (np.array): numpy array with true labels of test data\n",
    "    \n",
    "    Outputs:\n",
    "    plot of ROC\n",
    "    \n",
    "    '''\n",
    "    model_roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label= 'Random Forest '+model_name+' (area = %0.2f)' % model_roc_auc, color='darkblue')\n",
    "    plt.plot([0,1], [0,1], 'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic - '+e)\n",
    "    plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 8\n",
    "def plot_prc(model, X_test, y_test, y_pred):\n",
    "    '''\n",
    "    Function to plot Receiver Operating Curve in desired layout\n",
    "    \n",
    "    Inputs:\n",
    "    model: on a training set fitted and on a test set tested model\n",
    "    X_test (np.array): numpy array with feature vectors of test data\n",
    "    y_test (np.array): numpy array with true labels of test data\n",
    "    y_pred (np.array): numpy array with predictions of test data\n",
    "    \n",
    "    Outputs:\n",
    "    plot of Precision Recall Curve\n",
    "    '''\n",
    "    \n",
    "    average_precision = average_precision_score(y_test, y_pred)\n",
    "    print('Average precision-recall score: {0:0.4f}'.format(average_precision))\n",
    "    \n",
    "    disp = plot_precision_recall_curve(model, X_test, y_test, color='darkblue')\n",
    "    disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                      'AP={0:0.4f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 8\n",
    "def plot_actual_predicted_values(X_test_vis, y_test, y_pred):\n",
    "    '''\n",
    "    Function to plot actual and predicted values in desired layout \n",
    "    \n",
    "    Inputs:\n",
    "    model: on a training set fitted and on a test set tested model\n",
    "    X_test_vis (np.array): numpy array with feature vectors of test data \n",
    "                            including columns of month, day, year, hour, minute, second (not one-hot encoded)\n",
    "    y_test (np.array): numpy array with true labels of test data\n",
    "    y_pred (np.array): numpy array with predictions of test data\n",
    "    \n",
    "    Outputs:\n",
    "    plot of actual an predicted values\n",
    "    \n",
    "    '''\n",
    "    # Dates of testing data/predictions\n",
    "    months = X_test_vis[:, data_list.index('Month')]\n",
    "    days = X_test_vis[:, data_list.index('Day')]\n",
    "    years = X_test_vis[:, data_list.index('Year')]\n",
    "    hours = X_test_vis[:, data_list.index('Hour')]\n",
    "    minutes = X_test_vis[:, data_list.index('Minute')]\n",
    "    seconds = X_test_vis[:, data_list.index('Second')]\n",
    "    \n",
    "    # List and then convert to datetime object\n",
    "    test_dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) + ' ' + str(int(hour)) + ':' + str(int(minute)) + ':' + str(int(second)) \n",
    "                                                                                      for year, month, day, hour, minute, second in zip(years, months, days, hours, minutes, seconds)]\n",
    "\n",
    "    test_dates = [datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S') for date in test_dates]\n",
    "\n",
    "    # Dataframe with true values and dates\n",
    "    true_data = pd.DataFrame(data = {'date': test_dates, 'actual': y_test})\n",
    "\n",
    "    # Dataframe with predictions and dates\n",
    "    predictions_data = pd.DataFrame(data = {'date': test_dates, 'prediction': y_pred})\n",
    "    \n",
    "    # Plot the actual values\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.plot(true_data['date'], true_data['actual'],'darkblue', label = 'tatsächlicher Wert')\n",
    "    #plt.plot(true_data['date'], true_data['actual'],'darkblue', label = 'actual')\n",
    "    # Plot the predicted values\n",
    "    plt.plot(predictions_data['date'], predictions_data['prediction'], 'ro', label = 'vorhergesagter Wert')\n",
    "    #plt.plot(predictions_data['date'], predictions_data['prediction'], 'ro', label = 'prediction')\n",
    "    plt.xticks(rotation = '60');\n",
    "    plt.xlim(13330, 13515)\n",
    "    plt.yticks([0,1])\n",
    "    plt.legend()\n",
    "    # Graph labels\n",
    "    plt.xlabel('Datum'); plt.ylabel('Belegung'); plt.title('Tatsächliche und vorhergesagte Werte - '+e);\n",
    "    #plt.xlabel('Date'); plt.ylabel('Occupancy'); plt.title('Actual and Predicted Values');\n",
    "    # Dataframe with test values and dates\n",
    "    testing_data = pd.DataFrame(data = {'date': test_dates, 'actual': y_test})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = room number\n",
    "a = 'E07'\n",
    "# b = number of lags as input\n",
    "b = '5'\n",
    "# c = number of last timestep to predict\n",
    "c = 36\n",
    "# t = timesteps for seperate plots\n",
    "t = [6, 12, 18, 24, 30, 36]\n",
    "# d = number of timestep to predict\n",
    "# e = timestep in format 't+x' as string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | Description |\n",
    "| :- | :- |\n",
    "| a | room number |\n",
    "| b | number of lags as input | \n",
    "| c | number of last timestep to predict e.g. c=6 for t+6 |\n",
    "| d | number of timestep as running index in for loop |\n",
    "| e | timestep expression as string |\n",
    "| t | list with timesteps for seperate plots | \n",
    "| raw_data | raw dataset from csv file |\n",
    "| data | dataset that is used as copy raw_data |\n",
    "| data_copy | copy of dataset before it is transformed into a numpy array |\n",
    "| data_list | list of all features (column names) |\n",
    "| feature_names | list of all features without not one hot encoded features ('Year', 'Month','Day','Hour','Minute','Second','Weekday Name') |\n",
    "| labels | values we want to predict as numpy array of the whole dataset |\n",
    "| train_data | training set which is split into training and validation set later |\n",
    "| test_data | test set |\n",
    "| train_labels | training labels which is split into training and validation labels later|\n",
    "| test_labels | test labels |\n",
    "| tscv | Time Series Split for Cross Validation |\n",
    "| cv_train | training set for cross validation |\n",
    "| cv_val | validation set for cross validation |\n",
    "| cv_train_labels | training labels for cross validation | \n",
    "| cv_val_labels | validation labels for cross validation | \n",
    "| predictions | |\n",
    "| true_values | | \n",
    "#| validation_data | validation set |\n",
    "#| validation_labels | validation labels |\n",
    "| rf | Random Forest Classifier |\n",
    "| | |\n",
    "| | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t+1\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.972518457752256\n",
      "Precision: 0.9162779278173336\n",
      "Recall: 0.9189854715587293\n",
      "F1-Score: 0.917629702483403\n",
      "MCC: 0.9011392564788097\n",
      "Average precision-recall score: 0.8555\n",
      "Number of features for 95% importance:  46\n",
      "Number of features for 90% importance:  25\n",
      "[[19978   341]\n",
      " [  329  3732]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9730106644790812\n",
      "Precision: 0.9173411822418445\n",
      "Recall: 0.920955429697119\n",
      "F1-Score: 0.9191447530105677\n",
      "MCC: 0.9029492233701002\n",
      "Average precision-recall score: 0.8580\n",
      "Number of features for 95% importance:  41\n",
      "Number of features for 90% importance:  18\n",
      "[[19982   337]\n",
      " [  321  3740]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9710828547990156\n",
      "Precision: 0.9133004926108375\n",
      "Recall: 0.9130755971435607\n",
      "F1-Score: 0.9131880310306613\n",
      "MCC: 0.8958401733119499\n",
      "[[19967   352]\n",
      " [  353  3708]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9710828547990156\n",
      "Precision: 0.9133004926108375\n",
      "Recall: 0.9130755971435607\n",
      "F1-Score: 0.9131880310306613\n",
      "MCC: 0.8958401733119499\n",
      "[[19967   352]\n",
      " [  353  3708]]\n",
      "t+2\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9551681706316653\n",
      "Precision: 0.8704766658347891\n",
      "Recall: 0.8586903003446578\n",
      "F1-Score: 0.8645433139174619\n",
      "MCC: 0.8377117762084481\n",
      "Average precision-recall score: 0.7710\n",
      "Number of features for 95% importance:  59\n",
      "Number of features for 90% importance:  38\n",
      "[[19799   519]\n",
      " [  574  3488]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9548400328137818\n",
      "Precision: 0.8647450110864745\n",
      "Recall: 0.8641063515509602\n",
      "F1-Score: 0.8644255633542668\n",
      "MCC: 0.83733344796784\n",
      "Average precision-recall score: 0.7699\n",
      "Number of features for 95% importance:  55\n",
      "Number of features for 90% importance:  34\n",
      "[[19769   549]\n",
      " [  552  3510]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9480721903199344\n",
      "Precision: 0.8443349753694581\n",
      "Recall: 0.843919251600197\n",
      "F1-Score: 0.8441270622999261\n",
      "MCC: 0.8129739921228303\n",
      "[[19686   632]\n",
      " [  634  3428]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9480721903199344\n",
      "Precision: 0.8443349753694581\n",
      "Recall: 0.843919251600197\n",
      "F1-Score: 0.8441270622999261\n",
      "MCC: 0.8129739921228303\n",
      "[[19686   632]\n",
      " [  634  3428]]\n",
      "t+3\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9445857260049221\n",
      "Precision: 0.8236276849642005\n",
      "Recall: 0.8493723849372385\n",
      "F1-Score: 0.8363019508057676\n",
      "MCC: 0.8030969766384494\n",
      "Average precision-recall score: 0.7247\n",
      "Number of features for 95% importance:  62\n",
      "Number of features for 90% importance:  45\n",
      "[[19578   739]\n",
      " [  612  3451]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9448318293683347\n",
      "Precision: 0.8237255836112435\n",
      "Recall: 0.8510952498154073\n",
      "F1-Score: 0.8371867812613485\n",
      "MCC: 0.8041424086500181\n",
      "Average precision-recall score: 0.7259\n",
      "Number of features for 95% importance:  58\n",
      "Number of features for 90% importance:  42\n",
      "[[19577   740]\n",
      " [  605  3458]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9311320754716981\n",
      "Precision: 0.7935960591133004\n",
      "Recall: 0.793010091065715\n",
      "F1-Score: 0.793302966884156\n",
      "MCC: 0.7519860211278561\n",
      "[[19479   838]\n",
      " [  841  3222]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9311320754716981\n",
      "Precision: 0.7935960591133004\n",
      "Recall: 0.793010091065715\n",
      "F1-Score: 0.793302966884156\n",
      "MCC: 0.7519860211278561\n",
      "[[19479   838]\n",
      " [  841  3222]]\n",
      "t+4\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9340853158326498\n",
      "Precision: 0.8010291595197255\n",
      "Recall: 0.8043799212598425\n",
      "F1-Score: 0.8027010435850215\n",
      "MCC: 0.7631369837071426\n",
      "Average precision-recall score: 0.6769\n",
      "Number of features for 95% importance:  65\n",
      "Number of features for 90% importance:  48\n",
      "[[19504   812]\n",
      " [  795  3269]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9345365053322395\n",
      "Precision: 0.7993692382338671\n",
      "Recall: 0.8107775590551181\n",
      "F1-Score: 0.8050329831419496\n",
      "MCC: 0.7657275790966713\n",
      "Average precision-recall score: 0.6797\n",
      "Number of features for 95% importance:  62\n",
      "Number of features for 90% importance:  46\n",
      "[[19489   827]\n",
      " [  769  3295]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9182116488925348\n",
      "Precision: 0.7549261083743842\n",
      "Recall: 0.7541830708661418\n",
      "F1-Score: 0.7545544066962088\n",
      "MCC: 0.705484753760719\n",
      "[[19321   995]\n",
      " [  999  3065]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9182116488925348\n",
      "Precision: 0.7549261083743842\n",
      "Recall: 0.7541830708661418\n",
      "F1-Score: 0.7545544066962088\n",
      "MCC: 0.705484753760719\n",
      "[[19321   995]\n",
      " [  999  3065]]\n",
      "t+5\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9287120590648072\n",
      "Precision: 0.7800240673886883\n",
      "Recall: 0.7972939729397294\n",
      "F1-Score: 0.7885644768856448\n",
      "MCC: 0.7457640850371602\n",
      "Average precision-recall score: 0.6557\n",
      "Number of features for 95% importance:  66\n",
      "Number of features for 90% importance:  51\n",
      "[[19401   914]\n",
      " [  824  3241]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9286710418375718\n",
      "Precision: 0.7813255926463474\n",
      "Recall: 0.7945879458794588\n",
      "F1-Score: 0.7879009635321381\n",
      "MCC: 0.7450690459937391\n",
      "Average precision-recall score: 0.6551\n",
      "Number of features for 95% importance:  65\n",
      "Number of features for 90% importance:  50\n",
      "[[19411   904]\n",
      " [  835  3230]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9083264971287941\n",
      "Precision: 0.7253694581280788\n",
      "Recall: 0.7244772447724477\n",
      "F1-Score: 0.7249230769230769\n",
      "MCC: 0.6699214388650678\n",
      "[[19200  1115]\n",
      " [ 1120  2945]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8910172272354389\n",
      "Precision: 0.6815368746776689\n",
      "Recall: 0.6501845018450184\n",
      "F1-Score: 0.66549162784842\n",
      "MCC: 0.6006768522998415\n",
      "[[19080  1235]\n",
      " [ 1422  2643]]\n",
      "t+6\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9219031993437243\n",
      "Precision: 0.7674418604651163\n",
      "Recall: 0.7629119527791441\n",
      "F1-Score: 0.7651702022693637\n",
      "MCC: 0.7183386579763522\n",
      "Average precision-recall score: 0.6250\n",
      "Number of features for 95% importance:  67\n",
      "Number of features for 90% importance:  53\n",
      "[[19374   940]\n",
      " [  964  3102]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9241181296144381\n",
      "Precision: 0.7638095238095238\n",
      "Recall: 0.7889818002951303\n",
      "F1-Score: 0.7761916283571255\n",
      "MCC: 0.730659505531604\n",
      "Average precision-recall score: 0.6378\n",
      "Number of features for 95% importance:  68\n",
      "Number of features for 90% importance:  52\n",
      "[[19322   992]\n",
      " [  858  3208]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.900656275635767\n",
      "Precision: 0.7024630541871921\n",
      "Recall: 0.7014264633546483\n",
      "F1-Score: 0.7019443760767905\n",
      "MCC: 0.6423394105242146\n",
      "[[19106  1208]\n",
      " [ 1214  2852]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8836341263330599\n",
      "Precision: 0.6579285530711899\n",
      "Recall: 0.6296114117068372\n",
      "F1-Score: 0.6434585899208245\n",
      "MCC: 0.5741678746076376\n",
      "[[18983  1331]\n",
      " [ 1506  2560]]\n",
      "t+7\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9175553732567678\n",
      "Precision: 0.7547683923705722\n",
      "Recall: 0.7492008851733465\n",
      "F1-Score: 0.7519743336623891\n",
      "MCC: 0.7025428731674006\n",
      "Average precision-recall score: 0.6073\n",
      "Number of features for 95% importance:  66\n",
      "Number of features for 90% importance:  54\n",
      "[[19323   990]\n",
      " [ 1020  3047]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9215340442986054\n",
      "Precision: 0.759018759018759\n",
      "Recall: 0.776001967051881\n",
      "F1-Score: 0.7674164133738602\n",
      "MCC: 0.7202933695278072\n",
      "Average precision-recall score: 0.6264\n",
      "Number of features for 95% importance:  70\n",
      "Number of features for 90% importance:  55\n",
      "[[19311  1002]\n",
      " [  911  3156]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8939704675963905\n",
      "Precision: 0.6825123152709359\n",
      "Recall: 0.6813375952790754\n",
      "F1-Score: 0.6819244493663097\n",
      "MCC: 0.618306594950142\n",
      "[[19024  1289]\n",
      " [ 1296  2771]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8758408531583265\n",
      "Precision: 0.6363398007341374\n",
      "Recall: 0.596754364396361\n",
      "F1-Score: 0.6159116863342216\n",
      "MCC: 0.5423524896654469\n",
      "[[18926  1387]\n",
      " [ 1640  2427]]\n",
      "t+8\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9189909762100082\n",
      "Precision: 0.7628736498367245\n",
      "Recall: 0.7465585054080629\n",
      "F1-Score: 0.7546279040874642\n",
      "MCC: 0.7061811808708471\n",
      "Average precision-recall score: 0.6118\n",
      "Number of features for 95% importance:  69\n",
      "Number of features for 90% importance:  56\n",
      "[[19368   944]\n",
      " [ 1031  3037]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9178424938474159\n",
      "Precision: 0.7567769211638896\n",
      "Recall: 0.7480334316617503\n",
      "F1-Score: 0.7523797750030907\n",
      "MCC: 0.7031499778788146\n",
      "Average precision-recall score: 0.6081\n",
      "Number of features for 95% importance:  69\n",
      "Number of features for 90% importance:  56\n",
      "[[19334   978]\n",
      " [ 1025  3043]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8680065627563577\n",
      "Precision: 0.6140021459227468\n",
      "Recall: 0.5626843657817109\n",
      "F1-Score: 0.5872242175474602\n",
      "MCC: 0.5095317489201355\n",
      "[[18873  1439]\n",
      " [ 1779  2289]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.868785890073831\n",
      "Precision: 0.6142519063896924\n",
      "Recall: 0.5742379547689282\n",
      "F1-Score: 0.593571337822386\n",
      "MCC: 0.5158566170117129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18845  1467]\n",
      " [ 1732  2336]]\n",
      "t+9\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9150123051681707\n",
      "Precision: 0.7599583441812028\n",
      "Recall: 0.7173752764807078\n",
      "F1-Score: 0.7380530973451327\n",
      "MCC: 0.6877883113510006\n",
      "Average precision-recall score: 0.5923\n",
      "Number of features for 95% importance:  70\n",
      "Number of features for 90% importance:  57\n",
      "[[19389   922]\n",
      " [ 1150  2919]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9153814602132896\n",
      "Precision: 0.7565217391304347\n",
      "Recall: 0.726959941017449\n",
      "F1-Score: 0.7414462965283871\n",
      "MCC: 0.6910791854981235\n",
      "Average precision-recall score: 0.5955\n",
      "Number of features for 95% importance:  71\n",
      "Number of features for 90% importance:  58\n",
      "[[19359   952]\n",
      " [ 1111  2958]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8627563576702215\n",
      "Precision: 0.5993404781533388\n",
      "Recall: 0.5360039321700664\n",
      "F1-Score: 0.5659055526725479\n",
      "MCC: 0.4857665774815728\n",
      "[[18853  1458]\n",
      " [ 1888  2181]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8471287940935193\n",
      "Precision: 0.610608020698577\n",
      "Recall: 0.23199803391496682\n",
      "F1-Score: 0.3362422083704363\n",
      "MCC: 0.3096250660669116\n",
      "[[19709   602]\n",
      " [ 3125   944]]\n",
      "t+10\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9127563576702215\n",
      "Precision: 0.7444025157232704\n",
      "Recall: 0.727027027027027\n",
      "F1-Score: 0.7356121814791797\n",
      "MCC: 0.6834480584045831\n",
      "Average precision-recall score: 0.5868\n",
      "Number of features for 95% importance:  72\n",
      "Number of features for 90% importance:  60\n",
      "[[19294  1016]\n",
      " [ 1111  2959]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9102543068088598\n",
      "Precision: 0.7315452755905512\n",
      "Recall: 0.7304668304668305\n",
      "F1-Score: 0.7310056552741578\n",
      "MCC: 0.6771488200014136\n",
      "Average precision-recall score: 0.5794\n",
      "Number of features for 95% importance:  71\n",
      "Number of features for 90% importance:  58\n",
      "[[19219  1091]\n",
      " [ 1097  2973]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8568088597210829\n",
      "Precision: 0.580528511821975\n",
      "Recall: 0.5127764127764127\n",
      "F1-Score: 0.544553163731246\n",
      "MCC: 0.4612371864091488\n",
      "[[18802  1508]\n",
      " [ 1983  2087]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.847292863002461\n",
      "Precision: 0.5774207942882642\n",
      "Recall: 0.3179361179361179\n",
      "F1-Score: 0.4100776422120108\n",
      "MCC: 0.3502000337528492\n",
      "[[19363   947]\n",
      " [ 2776  1294]]\n",
      "t+11\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.907752255947498\n",
      "Precision: 0.7323979591836735\n",
      "Recall: 0.705232129697863\n",
      "F1-Score: 0.7185583781754475\n",
      "MCC: 0.6635869372152342\n",
      "Average precision-recall score: 0.5657\n",
      "Number of features for 95% importance:  72\n",
      "Number of features for 90% importance:  59\n",
      "[[19260  1049]\n",
      " [ 1200  2871]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9090237899917966\n",
      "Precision: 0.7364123500893085\n",
      "Recall: 0.7089167280766396\n",
      "F1-Score: 0.7224030037546934\n",
      "MCC: 0.6681967472832901\n",
      "Average precision-recall score: 0.5707\n",
      "Number of features for 95% importance:  71\n",
      "Number of features for 90% importance:  59\n",
      "[[19276  1033]\n",
      " [ 1185  2886]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8444626743232158\n",
      "Precision: 0.5768595041322314\n",
      "Recall: 0.2571849668386146\n",
      "F1-Score: 0.35575942915392456\n",
      "MCC: 0.31168401429278586\n",
      "[[19541   768]\n",
      " [ 3024  1047]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8488515176374077\n",
      "Precision: 0.5729402872260015\n",
      "Recall: 0.3723900761483665\n",
      "F1-Score: 0.4513919904719369\n",
      "MCC: 0.37979243412835473\n",
      "[[19179  1130]\n",
      " [ 2555  1516]]\n",
      "t+12\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9045529122231337\n",
      "Precision: 0.7319861738899229\n",
      "Recall: 0.6760805500982319\n",
      "F1-Score: 0.7029235286607941\n",
      "MCC: 0.6468966477722768\n",
      "Average precision-recall score: 0.5490\n",
      "Number of features for 95% importance:  73\n",
      "Number of features for 90% importance:  60\n",
      "[[19300  1008]\n",
      " [ 1319  2753]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9082854799015586\n",
      "Precision: 0.7374547335747542\n",
      "Recall: 0.700147347740668\n",
      "F1-Score: 0.7183169564121945\n",
      "MCC: 0.663905572389636\n",
      "Average precision-recall score: 0.5664\n",
      "Number of features for 95% importance:  71\n",
      "Number of features for 90% importance:  59\n",
      "[[19293  1015]\n",
      " [ 1221  2851]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8460623461853979\n",
      "Precision: 0.5802717664821339\n",
      "Recall: 0.2831532416502947\n",
      "F1-Score: 0.3805908565769929\n",
      "MCC: 0.3300285358501065\n",
      "[[19474   834]\n",
      " [ 2919  1153]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8447087776866283\n",
      "Precision: 0.5518115942028986\n",
      "Recall: 0.37401768172888017\n",
      "F1-Score: 0.4458430913348947\n",
      "MCC: 0.3685921535965289\n",
      "[[19071  1237]\n",
      " [ 2549  1523]]\n",
      "t+13\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9028712059064807\n",
      "Precision: 0.7319727891156462\n",
      "Recall: 0.6604468450773385\n",
      "F1-Score: 0.6943727413526072\n",
      "MCC: 0.6380043482640771\n",
      "Average precision-recall score: 0.5402\n",
      "Number of features for 95% importance:  72\n",
      "Number of features for 90% importance:  60\n",
      "[[19322   985]\n",
      " [ 1383  2690]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9059885151763741\n",
      "Precision: 0.7307592640580461\n",
      "Recall: 0.6923643506015222\n",
      "F1-Score: 0.7110438729198183\n",
      "MCC: 0.6552948715966602\n",
      "Average precision-recall score: 0.5573\n",
      "Number of features for 95% importance:  74\n",
      "Number of features for 90% importance:  61\n",
      "[[19268  1039]\n",
      " [ 1253  2820]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8440114848236259\n",
      "Precision: 0.5614754098360656\n",
      "Recall: 0.30272526393321875\n",
      "F1-Score: 0.3933641729143404\n",
      "MCC: 0.33265973654645664\n",
      "[[19344   963]\n",
      " [ 2840  1233]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8420016406890894\n",
      "Precision: 0.5373689550219818\n",
      "Recall: 0.39013012521482937\n",
      "F1-Score: 0.4520625889046942\n",
      "MCC: 0.36880740390169586\n",
      "[[18939  1368]\n",
      " [ 2484  1589]]\n",
      "t+14\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9029122231337161\n",
      "Precision: 0.7276607095225394\n",
      "Recall: 0.6696121747668139\n",
      "F1-Score: 0.6974306532020963\n",
      "MCC: 0.640513063130029\n",
      "Average precision-recall score: 0.5425\n",
      "Number of features for 95% importance:  73\n",
      "Number of features for 90% importance:  61\n",
      "[[19285  1021]\n",
      " [ 1346  2728]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9021739130434783\n",
      "Precision: 0.7290480065093572\n",
      "Recall: 0.6597938144329897\n",
      "F1-Score: 0.6926942404329339\n",
      "MCC: 0.6358120280684768\n",
      "Average precision-recall score: 0.5379\n",
      "Number of features for 95% importance:  74\n",
      "Number of features for 90% importance:  61\n",
      "[[19307   999]\n",
      " [ 1386  2688]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8408531583264971\n",
      "Precision: 0.5456255879586077\n",
      "Recall: 0.2847324496809033\n",
      "F1-Score: 0.3741935483870968\n",
      "MCC: 0.31360214806562803\n",
      "[[19340   966]\n",
      " [ 2914  1160]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8393355209187859\n",
      "Precision: 0.529500187899286\n",
      "Recall: 0.34585174275895925\n",
      "F1-Score: 0.41841128433556046\n",
      "MCC: 0.34001409681594685\n",
      "[[19054  1252]\n",
      " [ 2665  1409]]\n",
      "t+15\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9022149302707138\n",
      "Precision: 0.7303187142467993\n",
      "Recall: 0.6579141104294478\n",
      "F1-Score: 0.6922282468370772\n",
      "MCC: 0.6355112562663903\n",
      "Average precision-recall score: 0.5377\n",
      "Number of features for 95% importance:  74\n",
      "Number of features for 90% importance:  61\n",
      "[[19315   990]\n",
      " [ 1394  2681]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.907383100902379\n",
      "Precision: 0.7380141472360493\n",
      "Recall: 0.6912883435582822\n",
      "F1-Score: 0.713887480993411\n",
      "MCC: 0.6592082884179584\n",
      "Average precision-recall score: 0.5618\n",
      "Number of features for 95% importance:  74\n",
      "Number of features for 90% importance:  61\n",
      "[[19305  1000]\n",
      " [ 1258  2817]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8354388843314192\n",
      "Precision: 0.516466283324621\n",
      "Recall: 0.24245398773006135\n",
      "F1-Score: 0.3299933199732799\n",
      "MCC: 0.27319839103799193\n",
      "[[19380   925]\n",
      " [ 3087   988]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.836177194421657\n",
      "Precision: 0.5164300202839757\n",
      "Recall: 0.31239263803680983\n",
      "F1-Score: 0.3892966360856269\n",
      "MCC: 0.3139683226275257\n",
      "[[19113  1192]\n",
      " [ 2802  1273]]\n",
      "t+16\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.899712879409352\n",
      "Precision: 0.7244701348747592\n",
      "Recall: 0.6457311089303238\n",
      "F1-Score: 0.6828382410169931\n",
      "MCC: 0.6249674030910933\n",
      "Average precision-recall score: 0.5270\n",
      "Number of features for 95% importance:  74\n",
      "Number of features for 90% importance:  61\n",
      "[[19303  1001]\n",
      " [ 1444  2632]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9021328958162428\n",
      "Precision: 0.7298694232861807\n",
      "Recall: 0.658243375858685\n",
      "F1-Score: 0.6922084623323014\n",
      "MCC: 0.6354046454897522\n",
      "Average precision-recall score: 0.5376\n",
      "Number of features for 95% importance:  74\n",
      "Number of features for 90% importance:  61\n",
      "[[19311   993]\n",
      " [ 1393  2683]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8324446267432322\n",
      "Precision: 0.4971392244119517\n",
      "Recall: 0.1918547595682041\n",
      "F1-Score: 0.2768631616215259\n",
      "MCC: 0.23222457719427894\n",
      "[[19513   791]\n",
      " [ 3294   782]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8377358490566038\n",
      "Precision: 0.5262008733624454\n",
      "Recall: 0.29563297350343476\n",
      "F1-Score: 0.37857367263587816\n",
      "MCC: 0.3097832070563239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19219  1085]\n",
      " [ 2871  1205]]\n",
      "t+17\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8993027071369976\n",
      "Precision: 0.7197831978319783\n",
      "Recall: 0.6514594064262939\n",
      "F1-Score: 0.6839191451010687\n",
      "MCC: 0.6253057835393151\n",
      "Average precision-recall score: 0.5272\n",
      "Number of features for 95% importance:  75\n",
      "Number of features for 90% importance:  63\n",
      "[[19269  1034]\n",
      " [ 1421  2656]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9011484823625923\n",
      "Precision: 0.716662334286457\n",
      "Recall: 0.6762325239146432\n",
      "F1-Score: 0.6958606764260475\n",
      "MCC: 0.6372862191249208\n",
      "Average precision-recall score: 0.5388\n",
      "Number of features for 95% importance:  75\n",
      "Number of features for 90% importance:  63\n",
      "[[19213  1090]\n",
      " [ 1320  2757]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8313781788351108\n",
      "Precision: 0.4849557522123894\n",
      "Recall: 0.13441255825361786\n",
      "F1-Score: 0.21048588438640295\n",
      "MCC: 0.18770125515643543\n",
      "[[19721   582]\n",
      " [ 3529   548]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8395816242821985\n",
      "Precision: 0.5377959927140255\n",
      "Recall: 0.2896737797400049\n",
      "F1-Score: 0.3765343535788299\n",
      "MCC: 0.3124267987758453\n",
      "[[19288  1015]\n",
      " [ 2896  1181]]\n",
      "t+18\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8974159146841674\n",
      "Precision: 0.7223005356639414\n",
      "Recall: 0.6282491417361452\n",
      "F1-Score: 0.6719999999999999\n",
      "MCC: 0.6136399281184179\n",
      "Average precision-recall score: 0.5160\n",
      "Number of features for 95% importance:  74\n",
      "Number of features for 90% importance:  61\n",
      "[[19317   985]\n",
      " [ 1516  2562]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8987694831829368\n",
      "Precision: 0.7199453551912568\n",
      "Recall: 0.6461500735654733\n",
      "F1-Score: 0.6810545360558283\n",
      "MCC: 0.6223831381844243\n",
      "Average precision-recall score: 0.5244\n",
      "Number of features for 95% importance:  75\n",
      "Number of features for 90% importance:  63\n",
      "[[19277  1025]\n",
      " [ 1443  2635]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8316652994257588\n",
      "Precision: 0.48444976076555024\n",
      "Recall: 0.09931338891613536\n",
      "F1-Score: 0.16483516483516483\n",
      "MCC: 0.16014432480049468\n",
      "[[19871   431]\n",
      " [ 3673   405]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8338392124692371\n",
      "Precision: 0.5058926233085989\n",
      "Recall: 0.2842079450711133\n",
      "F1-Score: 0.3639503846757733\n",
      "MCC: 0.29220214973012854\n",
      "[[19170  1132]\n",
      " [ 2919  1159]]\n",
      "t+19\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8948318293683347\n",
      "Precision: 0.7074774034511093\n",
      "Recall: 0.633243442020103\n",
      "F1-Score: 0.6683053040103493\n",
      "MCC: 0.6073567098240868\n",
      "Average precision-recall score: 0.5094\n",
      "Number of features for 95% importance:  76\n",
      "Number of features for 90% importance:  63\n",
      "[[19233  1068]\n",
      " [ 1496  2583]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8977030352748154\n",
      "Precision: 0.7162346521145976\n",
      "Recall: 0.6435400833537632\n",
      "F1-Score: 0.6779442148760331\n",
      "MCC: 0.6185943751228741\n",
      "Average precision-recall score: 0.5206\n",
      "Number of features for 95% importance:  75\n",
      "Number of features for 90% importance:  63\n",
      "[[19261  1040]\n",
      " [ 1454  2625]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8314191960623462\n",
      "Precision: 0.28169014084507044\n",
      "Recall: 0.004903162539838196\n",
      "F1-Score: 0.00963855421686747\n",
      "MCC: 0.01656140431324698\n",
      "[[20250    51]\n",
      " [ 4059    20]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8319114027891714\n",
      "Precision: 0.49501835343471423\n",
      "Recall: 0.23142927188036283\n",
      "F1-Score: 0.3154026060808553\n",
      "MCC: 0.25575929910705275\n",
      "[[19338   963]\n",
      " [ 3135   944]]\n",
      "t+20\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8950369155045119\n",
      "Precision: 0.7174721189591078\n",
      "Recall: 0.6149509803921569\n",
      "F1-Score: 0.6622673881483437\n",
      "MCC: 0.6030674009784966\n",
      "Average precision-recall score: 0.5056\n",
      "Number of features for 95% importance:  76\n",
      "Number of features for 90% importance:  64\n",
      "[[19312   988]\n",
      " [ 1571  2509]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8930680885972109\n",
      "Precision: 0.7090547828555208\n",
      "Recall: 0.6122549019607844\n",
      "F1-Score: 0.6571090359068787\n",
      "MCC: 0.5964148409366201\n",
      "Average precision-recall score: 0.4990\n",
      "Number of features for 95% importance:  76\n",
      "Number of features for 90% importance:  64\n",
      "[[19275  1025]\n",
      " [ 1582  2498]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8317063166529942\n",
      "Precision: 0.2653061224489796\n",
      "Recall: 0.0031862745098039215\n",
      "F1-Score: 0.006296924194720272\n",
      "MCC: 0.011776167489374323\n",
      "[[20264    36]\n",
      " [ 4067    13]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8236259228876128\n",
      "Precision: 0.4422268907563025\n",
      "Recall: 0.20637254901960783\n",
      "F1-Score: 0.28141711229946526\n",
      "MCC: 0.21432228810471074\n",
      "[[19238  1062]\n",
      " [ 3238   842]]\n",
      "t+21\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8920426579163249\n",
      "Precision: 0.7127753303964758\n",
      "Recall: 0.59470717961284\n",
      "F1-Score: 0.6484103660165642\n",
      "MCC: 0.5886038101772598\n",
      "Average precision-recall score: 0.4917\n",
      "Number of features for 95% importance:  77\n",
      "Number of features for 90% importance:  65\n",
      "[[19321   978]\n",
      " [ 1654  2427]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8941345365053323\n",
      "Precision: 0.7151462994836488\n",
      "Recall: 0.6108796863513845\n",
      "F1-Score: 0.6589137042421038\n",
      "MCC: 0.5993111049213748\n",
      "Average precision-recall score: 0.5020\n",
      "Number of features for 95% importance:  77\n",
      "Number of features for 90% importance:  65\n",
      "[[19306   993]\n",
      " [ 1588  2493]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8311320754716981\n",
      "Precision: 0.23529411764705882\n",
      "Recall: 0.0039206076941926\n",
      "F1-Score: 0.007712701855868883\n",
      "MCC: 0.00961933308066692\n",
      "[[20247    52]\n",
      " [ 4065    16]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8216570959803118\n",
      "Precision: 0.43867707854846116\n",
      "Recall: 0.2340112717471208\n",
      "F1-Score: 0.30520933205496964\n",
      "MCC: 0.22754300426487073\n",
      "[[19077  1222]\n",
      " [ 3126   955]]\n",
      "t+22\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8896636587366694\n",
      "Precision: 0.7059171597633136\n",
      "Recall: 0.5845173934345909\n",
      "F1-Score: 0.6395068346287858\n",
      "MCC: 0.5786190919455172\n",
      "Average precision-recall score: 0.4822\n",
      "Number of features for 95% importance:  78\n",
      "Number of features for 90% importance:  66\n",
      "[[19304   994]\n",
      " [ 1696  2386]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8889253486464315\n",
      "Precision: 0.7011124121779859\n",
      "Recall: 0.5867221950024498\n",
      "F1-Score: 0.6388370232061883\n",
      "MCC: 0.5769968389155821\n",
      "Average precision-recall score: 0.4806\n",
      "Number of features for 95% importance:  78\n",
      "Number of features for 90% importance:  66\n",
      "[[19277  1021]\n",
      " [ 1687  2395]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8312551271534044\n",
      "Precision: 0.2714285714285714\n",
      "Recall: 0.0046545810877021065\n",
      "F1-Score: 0.009152215799614644\n",
      "MCC: 0.014946682055315571\n",
      "[[20247    51]\n",
      " [ 4063    19]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8187038556193601\n",
      "Precision: 0.4229014598540146\n",
      "Recall: 0.22709456148946594\n",
      "F1-Score: 0.2955052598023589\n",
      "MCC: 0.215065236702335\n",
      "[[19033  1265]\n",
      " [ 3155   927]]\n",
      "t+23\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8862182116488926\n",
      "Precision: 0.6894356005788712\n",
      "Recall: 0.5833945628214549\n",
      "F1-Score: 0.6319978774210666\n",
      "MCC: 0.5680132706057436\n",
      "Average precision-recall score: 0.4720\n",
      "Number of features for 95% importance:  78\n",
      "Number of features for 90% importance:  66\n",
      "[[19224  1073]\n",
      " [ 1701  2382]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8883100902378999\n",
      "Precision: 0.6971014492753623\n",
      "Recall: 0.5890276757286309\n",
      "F1-Score: 0.6385238284879862\n",
      "MCC: 0.5758694588913253\n",
      "Average precision-recall score: 0.4794\n",
      "Number of features for 95% importance:  77\n",
      "Number of features for 90% importance:  66\n",
      "[[19252  1045]\n",
      " [ 1678  2405]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anna-Lena\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Anna-Lena\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.832526661197703\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "MCC: 0.0\n",
      "[[20297     0]\n",
      " [ 4083     0]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8091468416735029\n",
      "Precision: 0.37554585152838427\n",
      "Recall: 0.2106294391378888\n",
      "F1-Score: 0.2698885924996077\n",
      "MCC: 0.17941662401227126\n",
      "[[18867  1430]\n",
      " [ 3223   860]]\n",
      "t+24\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8872026251025431\n",
      "Precision: 0.697014484185634\n",
      "Recall: 0.5775165319617928\n",
      "F1-Score: 0.6316635413876239\n",
      "MCC: 0.5692462400269303\n",
      "Average precision-recall score: 0.4733\n",
      "Number of features for 95% importance:  78\n",
      "Number of features for 90% importance:  66\n",
      "[[19272  1025]\n",
      " [ 1725  2358]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8893355209187859\n",
      "Precision: 0.7017186134576172\n",
      "Recall: 0.5900073475385745\n",
      "F1-Score: 0.6410324640766365\n",
      "MCC: 0.5792216152449376\n",
      "Average precision-recall score: 0.4827\n",
      "Number of features for 95% importance:  78\n",
      "Number of features for 90% importance:  66\n",
      "[[19273  1024]\n",
      " [ 1674  2409]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8317063166529942\n",
      "Precision: 0.2916666666666667\n",
      "Recall: 0.003428851334802841\n",
      "F1-Score: 0.006778019849915274\n",
      "MCC: 0.014772638309658638\n",
      "[[20263    34]\n",
      " [ 4069    14]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8071780147662018\n",
      "Precision: 0.3601809954751131\n",
      "Recall: 0.1949546901787901\n",
      "F1-Score: 0.2529795010328937\n",
      "MCC: 0.16294474020339306\n",
      "[[18883  1414]\n",
      " [ 3287   796]]\n",
      "t+25\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8800656275635766\n",
      "Precision: 0.6737631184407796\n",
      "Recall: 0.550330639235856\n",
      "F1-Score: 0.6058236721488273\n",
      "MCC: 0.5397600035610237\n",
      "Average precision-recall score: 0.4461\n",
      "Number of features for 95% importance:  79\n",
      "Number of features for 90% importance:  67\n",
      "[[19209  1088]\n",
      " [ 1836  2247]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.882239540607055\n",
      "Precision: 0.6761627906976744\n",
      "Recall: 0.5696791574822434\n",
      "F1-Score: 0.6183703309849794\n",
      "MCC: 0.5521685926532879\n",
      "Average precision-recall score: 0.4573\n",
      "Number of features for 95% importance:  79\n",
      "Number of features for 90% importance:  66\n",
      "[[19183  1114]\n",
      " [ 1757  2326]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8323215750615258\n",
      "Precision: 0.3076923076923077\n",
      "Recall: 0.0009796718099436689\n",
      "F1-Score: 0.001953125\n",
      "MCC: 0.008673722012008373\n",
      "[[20288     9]\n",
      " [ 4079     4]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8004922067268253\n",
      "Precision: 0.3431096826034552\n",
      "Recall: 0.20915993142297332\n",
      "F1-Score: 0.25989044430919056\n",
      "MCC: 0.1586069161819108\n",
      "[[18662  1635]\n",
      " [ 3229   854]]\n",
      "t+26\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8821985233798195\n",
      "Precision: 0.6818864523881045\n",
      "Recall: 0.5559637521430321\n",
      "F1-Score: 0.6125202374527793\n",
      "MCC: 0.5478487166601425\n",
      "Average precision-recall score: 0.4535\n",
      "Number of features for 95% importance:  79\n",
      "Number of features for 90% importance:  67\n",
      "[[19238  1059]\n",
      " [ 1813  2270]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.880188679245283\n",
      "Precision: 0.6808841843088418\n",
      "Recall: 0.5356355620867009\n",
      "F1-Score: 0.5995887594242633\n",
      "MCC: 0.5356005064454844\n",
      "Average precision-recall score: 0.4425\n",
      "Number of features for 95% importance:  81\n",
      "Number of features for 90% importance:  69\n",
      "[[19272  1025]\n",
      " [ 1896  2187]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8314602132895816\n",
      "Precision: 0.2833333333333333\n",
      "Recall: 0.004163605192260593\n",
      "F1-Score: 0.008206613565049481\n",
      "MCC: 0.015411873263314606\n",
      "[[20254    43]\n",
      " [ 4066    17]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8287940935192781\n",
      "Precision: 0.4025695931477516\n",
      "Recall: 0.04604457506735244\n",
      "F1-Score: 0.08263736263736264\n",
      "MCC: 0.08798633008568717\n",
      "[[20018   279]\n",
      " [ 3895   188]]\n",
      "t+27\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8846595570139458\n",
      "Precision: 0.6889681831697889\n",
      "Recall: 0.5674748959098702\n",
      "F1-Score: 0.6223475691646522\n",
      "MCC: 0.558671061804567\n",
      "Average precision-recall score: 0.4634\n",
      "Number of features for 95% importance:  80\n",
      "Number of features for 90% importance:  68\n",
      "[[19251  1046]\n",
      " [ 1766  2317]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8835931091058244\n",
      "Precision: 0.6840082766775052\n",
      "Recall: 0.5667401420524124\n",
      "F1-Score: 0.6198767747120278\n",
      "MCC: 0.5552648246344534\n",
      "Average precision-recall score: 0.4602\n",
      "Number of features for 95% importance:  80\n",
      "Number of features for 90% importance:  69\n",
      "[[19228  1069]\n",
      " [ 1769  2314]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8326497128794094\n",
      "Precision: 1.0\n",
      "Recall: 0.0007347538574577516\n",
      "F1-Score: 0.0014684287812041115\n",
      "MCC: 0.0247341354406461\n",
      "[[20297     0]\n",
      " [ 4080     3]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8256357670221492\n",
      "Precision: 0.37037037037037035\n",
      "Recall: 0.05878030859662013\n",
      "F1-Score: 0.1014584654407102\n",
      "MCC: 0.08978920200401524\n",
      "[[19889   408]\n",
      " [ 3843   240]]\n",
      "t+28\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.882895816242822\n",
      "Precision: 0.6796372147454652\n",
      "Recall: 0.5689444036247857\n",
      "F1-Score: 0.6193840821223837\n",
      "MCC: 0.5538685426467307\n",
      "Average precision-recall score: 0.4589\n",
      "Number of features for 95% importance:  79\n",
      "Number of features for 90% importance:  69\n",
      "[[19202  1095]\n",
      " [ 1760  2323]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.881214109926169\n",
      "Precision: 0.6849485821128077\n",
      "Recall: 0.538329659564046\n",
      "F1-Score: 0.6028524410312671\n",
      "MCC: 0.5395501720296496\n",
      "Average precision-recall score: 0.4460\n",
      "Number of features for 95% importance:  81\n",
      "Number of features for 90% importance:  70\n",
      "[[19286  1011]\n",
      " [ 1885  2198]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8282608695652174\n",
      "Precision: 0.25925925925925924\n",
      "Recall: 0.013715405339211364\n",
      "F1-Score: 0.02605257036520121\n",
      "MCC: 0.023240561418040033\n",
      "[[20137   160]\n",
      " [ 4027    56]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.7990155865463495\n",
      "Precision: 0.30667297681022243\n",
      "Recall: 0.15870683321087437\n",
      "F1-Score: 0.2091672046481601\n",
      "MCC: 0.11483785853862721\n",
      "[[18832  1465]\n",
      " [ 3435   648]]\n",
      "t+29\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8827727645611156\n",
      "Precision: 0.6802000588408356\n",
      "Recall: 0.5662503061474407\n",
      "F1-Score: 0.6180165731087944\n",
      "MCC: 0.5526835348044837\n",
      "Average precision-recall score: 0.4578\n",
      "Number of features for 95% importance:  79\n",
      "Number of features for 90% importance:  68\n",
      "[[19210  1087]\n",
      " [ 1771  2312]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8842493847415914\n",
      "Precision: 0.6896240601503759\n",
      "Recall: 0.5615968650502082\n",
      "F1-Score: 0.619060475161987\n",
      "MCC: 0.5557022685544347\n",
      "Average precision-recall score: 0.4607\n",
      "Number of features for 95% importance:  80\n",
      "Number of features for 90% importance:  69\n",
      "[[19265  1032]\n",
      " [ 1790  2293]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8292042657916325\n",
      "Precision: 0.36893203883495146\n",
      "Recall: 0.027920646583394562\n",
      "F1-Score: 0.05191256830601093\n",
      "MCC: 0.061128858494322\n",
      "[[20102   195]\n",
      " [ 3969   114]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.7901558654634947\n",
      "Precision: 0.2987923646279704\n",
      "Recall: 0.1878520695566985\n",
      "F1-Score: 0.2306766917293233\n",
      "MCC: 0.12064545688115628\n",
      "[[18497  1800]\n",
      " [ 3316   767]]\n",
      "t+30\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8840442986054142\n",
      "Precision: 0.689957652752571\n",
      "Recall: 0.5586578496203771\n",
      "F1-Score: 0.6174042495601569\n",
      "MCC: 0.5542162797915365\n",
      "Average precision-recall score: 0.4594\n",
      "Number of features for 95% importance:  79\n",
      "Number of features for 90% importance:  68\n",
      "[[19272  1025]\n",
      " [ 1802  2281]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8832239540607055\n",
      "Precision: 0.6945843828715366\n",
      "Recall: 0.5402890031839334\n",
      "F1-Score: 0.6077972172475548\n",
      "MCC: 0.5463381783232677\n",
      "Average precision-recall score: 0.4523\n",
      "Number of features for 95% importance:  80\n",
      "Number of features for 90% importance:  69\n",
      "[[19327   970]\n",
      " [ 1877  2206]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8253076292042658\n",
      "Precision: 0.3181818181818182\n",
      "Recall: 0.03771736468283125\n",
      "F1-Score: 0.06744033282242172\n",
      "MCC: 0.057441510191310434\n",
      "[[19967   330]\n",
      " [ 3929   154]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.7974979491386383\n",
      "Precision: 0.31353711790393013\n",
      "Recall: 0.17585108988488857\n",
      "F1-Score: 0.22532559234269575\n",
      "MCC: 0.12594777557854486\n",
      "[[18725  1572]\n",
      " [ 3365   718]]\n",
      "t+31\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8827727645611156\n",
      "Precision: 0.7028817489234847\n",
      "Recall: 0.5197158951751163\n",
      "F1-Score: 0.5975781470008448\n",
      "MCC: 0.539056194074407\n",
      "Average precision-recall score: 0.4457\n",
      "Number of features for 95% importance:  80\n",
      "Number of features for 90% importance:  69\n",
      "[[19400   897]\n",
      " [ 1961  2122]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8817473338802297\n",
      "Precision: 0.6940491591203105\n",
      "Recall: 0.5255939260347784\n",
      "F1-Score: 0.5981881533101047\n",
      "MCC: 0.5374540134011911\n",
      "Average precision-recall score: 0.4442\n",
      "Number of features for 95% importance:  80\n",
      "Number of features for 90% importance:  69\n",
      "[[19351   946]\n",
      " [ 1937  2146]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8289581624282198\n",
      "Precision: 0.32806324110671936\n",
      "Recall: 0.02032819005633113\n",
      "F1-Score: 0.038284132841328415\n",
      "MCC: 0.04404077145598195\n",
      "[[20127   170]\n",
      " [ 4000    83]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.7900738310090238\n",
      "Precision: 0.29537366548042704\n",
      "Recall: 0.18295371050698017\n",
      "F1-Score: 0.22595281306715065\n",
      "MCC: 0.11653020094600954\n",
      "[[18515  1782]\n",
      " [ 3336   747]]\n",
      "t+32\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8841673502871206\n",
      "Precision: 0.7019570099454604\n",
      "Recall: 0.5358804800391869\n",
      "F1-Score: 0.6077777777777778\n",
      "MCC: 0.5480480776548422\n",
      "Average precision-recall score: 0.4539\n",
      "Number of features for 95% importance:  80\n",
      "Number of features for 90% importance:  70\n",
      "[[19368   929]\n",
      " [ 1895  2188]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8824036095159967\n",
      "Precision: 0.7041638683680322\n",
      "Recall: 0.5135929463629684\n",
      "F1-Score: 0.5939668602180994\n",
      "MCC: 0.536151078713541\n",
      "Average precision-recall score: 0.4431\n",
      "Number of features for 95% importance:  81\n",
      "Number of features for 90% importance:  71\n",
      "[[19416   881]\n",
      " [ 1986  2097]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8266611977030353\n",
      "Precision: 0.28134556574923547\n",
      "Recall: 0.022532451628704386\n",
      "F1-Score: 0.041723356009070296\n",
      "MCC: 0.03555782188745814\n",
      "[[20062   235]\n",
      " [ 3991    92]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8024610336341264\n",
      "Precision: 0.30841610036591743\n",
      "Recall: 0.14450159196669116\n",
      "F1-Score: 0.19679786524349568\n",
      "MCC: 0.11014272181067292\n",
      "[[18974  1323]\n",
      " [ 3493   590]]\n",
      "t+33\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8813371616078753\n",
      "Precision: 0.7019687712152071\n",
      "Recall: 0.5064903257408768\n",
      "F1-Score: 0.5884194053208137\n",
      "MCC: 0.5306850360013907\n",
      "Average precision-recall score: 0.4382\n",
      "Number of features for 95% importance:  80\n",
      "Number of features for 90% importance:  70\n",
      "[[19419   878]\n",
      " [ 2015  2068]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8815422477440525\n",
      "Precision: 0.7049742710120068\n",
      "Recall: 0.5033063923585599\n",
      "F1-Score: 0.5873106601886253\n",
      "MCC: 0.5304703815792571\n",
      "Average precision-recall score: 0.4380\n",
      "Number of features for 95% importance:  80\n",
      "Number of features for 90% importance:  70\n",
      "[[19437   860]\n",
      " [ 2028  2055]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8316652994257588\n",
      "Precision: 0.36\n",
      "Recall: 0.006612784717119765\n",
      "F1-Score: 0.012987012987012986\n",
      "MCC: 0.028641897341083408\n",
      "[[20249    48]\n",
      " [ 4056    27]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.7967596390484003\n",
      "Precision: 0.3120689655172414\n",
      "Recall: 0.17732059759980406\n",
      "F1-Score: 0.22614399500234264\n",
      "MCC: 0.12558115753095625\n",
      "[[18701  1596]\n",
      " [ 3359   724]]\n",
      "t+34\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8792042657916325\n",
      "Precision: 0.6945964432284542\n",
      "Recall: 0.49742836149889785\n",
      "F1-Score: 0.5797060082774368\n",
      "MCC: 0.5211400395815889\n",
      "Average precision-recall score: 0.4297\n",
      "Number of features for 95% importance:  80\n",
      "Number of features for 90% importance:  70\n",
      "[[19404   893]\n",
      " [ 2052  2031]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.881214109926169\n",
      "Precision: 0.6969797543976104\n",
      "Recall: 0.5143277002204262\n",
      "F1-Score: 0.5918827508455468\n",
      "MCC: 0.5325091845604564\n",
      "Average precision-recall score: 0.4398\n",
      "Number of features for 95% importance:  80\n",
      "Number of features for 90% importance:  70\n",
      "[[19384   913]\n",
      " [ 1983  2100]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8273174733388023\n",
      "Precision: 0.20187793427230047\n",
      "Recall: 0.010531471956894441\n",
      "F1-Score: 0.020018621973929236\n",
      "MCC: 0.008650136722699283\n",
      "[[20127   170]\n",
      " [ 4040    43]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.794585726004922\n",
      "Precision: 0.2900590104403087\n",
      "Recall: 0.1565025716385011\n",
      "F1-Score: 0.2033089405027044\n",
      "MCC: 0.10347219133192849\n",
      "[[18733  1564]\n",
      " [ 3444   639]]\n",
      "t+35\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8774405250205086\n",
      "Precision: 0.6879505664263645\n",
      "Recall: 0.4908155767817781\n",
      "F1-Score: 0.5728987993138936\n",
      "MCC: 0.5134691814591126\n",
      "Average precision-recall score: 0.4229\n",
      "Number of features for 95% importance:  80\n",
      "Number of features for 90% importance:  70\n",
      "[[19388   909]\n",
      " [ 2079  2004]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8760459392945037\n",
      "Precision: 0.6841374522735162\n",
      "Recall: 0.48273328434974283\n",
      "F1-Score: 0.5660539919586444\n",
      "MCC: 0.5065226636780742\n",
      "Average precision-recall score: 0.4169\n",
      "Number of features for 95% importance:  80\n",
      "Number of features for 90% importance:  70\n",
      "[[19387   910]\n",
      " [ 2112  1971]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8260869565217391\n",
      "Precision: 0.2226148409893993\n",
      "Recall: 0.015429831006612785\n",
      "F1-Score: 0.02885936784241869\n",
      "MCC: 0.016003626518100684\n",
      "[[20077   220]\n",
      " [ 4020    63]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8134126333059886\n",
      "Precision: 0.2531779661016949\n",
      "Recall: 0.05853539064413422\n",
      "F1-Score: 0.09508653272329422\n",
      "MCC: 0.046065586891690234\n",
      "[[19592   705]\n",
      " [ 3844   239]]\n",
      "t+36\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8749794913863823\n",
      "Precision: 0.6839672947031639\n",
      "Recall: 0.47122214058290474\n",
      "F1-Score: 0.5580046403712298\n",
      "MCC: 0.4995550183279452\n",
      "Average precision-recall score: 0.4109\n",
      "Number of features for 95% importance:  81\n",
      "Number of features for 90% importance:  71\n",
      "[[19408   889]\n",
      " [ 2159  1924]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8735438884331419\n",
      "Precision: 0.6744591765526867\n",
      "Recall: 0.473426402155278\n",
      "F1-Score: 0.5563390415887178\n",
      "MCC: 0.49556591066215694\n",
      "Average precision-recall score: 0.4075\n",
      "Number of features for 95% importance:  80\n",
      "Number of features for 90% importance:  70\n",
      "[[19364   933]\n",
      " [ 2150  1933]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.829819524200164\n",
      "Precision: 0.25\n",
      "Recall: 0.008082292432035268\n",
      "F1-Score: 0.015658362989323844\n",
      "MCC: 0.016306898367891398\n",
      "[[20198    99]\n",
      " [ 4050    33]]\n",
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8178424938474159\n",
      "Precision: 0.289906103286385\n",
      "Recall: 0.060494734264021556\n",
      "F1-Score: 0.10010131712259372\n",
      "MCC: 0.06239546604468663\n",
      "[[19692   605]\n",
      " [ 3836   247]]\n"
     ]
    }
   ],
   "source": [
    "for d in range(1,c+1):\n",
    "    \n",
    "      \n",
    "    # Timestep as string\n",
    "    e = 't+'+str(d)\n",
    "    print(e)\n",
    "\n",
    "\n",
    "    #### IMPORT DATA\n",
    "\n",
    "    # Read in data and set index\n",
    "    raw_data = pd.read_csv(\"\\Pre-Processing\\data_E07_input_5_output_144.txt\", parse_dates=True)\n",
    "    data = raw_data.copy()\n",
    "    data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "    data = data.set_index('DateTime')\n",
    "\n",
    "\n",
    "\n",
    "    #### DATA PREPARATION\n",
    "\n",
    "    # Drop columns for Second\n",
    "    data = data.drop('Second_0', axis = 1)\n",
    "\n",
    "    # Drop columns of future timestamps that should not be used as input for this model\n",
    "    if d==0:\n",
    "        for i in range(1,145):\n",
    "            v = 't+'+str(i)\n",
    "            data = data.drop(v, axis = 1)\n",
    "    else:\n",
    "        for i in range(d+1,145):\n",
    "            v = 't+'+str(i)\n",
    "            data = data.drop(v, axis = 1)\n",
    "\n",
    "        for i in range(1, d):\n",
    "            v = 't+'+str(i)\n",
    "            data = data.drop(v, axis = 1)\n",
    "\n",
    "\n",
    "    # Add columns with year, month, day and weekday name at the end of the dataset for later use of visualization \n",
    "    data['Year'] = data.index.year\n",
    "    data['Month'] = data.index.month\n",
    "    data['Day'] = data.index.day\n",
    "    data['Weekday Name'] = data.index.day_name()\n",
    "    data['Hour'] = data.index.hour\n",
    "    data['Minute'] = data.index.minute\n",
    "    data['Second'] = data.index.second\n",
    "\n",
    "    # Use numpy to convert to arrays\n",
    "    # Labels are the values we want to predict\n",
    "    labels = np.array(data[e])\n",
    "\n",
    "    # Remove the labels from the data\n",
    "    # axis 1 refers to the columns\n",
    "    data = data.drop(e, axis = 1)\n",
    "\n",
    "    # Saving data names for later use\n",
    "    data_list = list(data.columns)\n",
    "\n",
    "    # Save copy before transforming to numpy array\n",
    "    data_copy = data.copy()\n",
    "\n",
    "    # Convert to numpy array\n",
    "    data = np.array(data)\n",
    "\n",
    "    # Extract only the one hot encoded data\n",
    "    feature_names = [i for i in data_list if i not in ['Year', 'Month','Day','Hour','Minute','Second','Weekday Name']]\n",
    "    indices = [data_list.index(feature_names[x]) for x in range(0,len(feature_names))]\n",
    "    data_to_use = data[:, indices]\n",
    "\n",
    "\n",
    "    ### SPLIT DATASET\n",
    "\n",
    "    # Split data into training and testing sets using scikit-learn \n",
    "    # 25% so that approximately the last 6 months are covered \n",
    "    # shuffle = False because of time series data\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(data_to_use, labels, test_size = 0.25, shuffle=False)\n",
    "    train_data_vis, test_data_vis, train_labels_vis, test_labels_vis = train_test_split(data, labels, test_size = 0.25, shuffle=False) \n",
    "\n",
    "\n",
    "    #### RANDOM FOREST MODELING\n",
    "\n",
    "    ### BASE MODEL\n",
    "\n",
    "    # Instantiate base model with 100 decision trees\n",
    "    rf_base = RandomForestClassifier(n_estimators = 100, random_state=42)\n",
    "    model_name = 'base'\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_base.fit(train_data, train_labels)\n",
    "\n",
    "    # Calculate accuracy on the training set\n",
    "    accuracy_train_rf_base = rf_base.score(train_data, train_labels)\n",
    "\n",
    "    # Make predictions on test set and calculate metrics\n",
    "    predictions_rf_base, metrics_rf_base, accuracy_rf_base, precision_rf_base, recall_rf_base, f1_rf_base, mcc_rf_base = predict_with_model(rf_base, test_data, test_labels)\n",
    "\n",
    "    # Calculate feature importances\n",
    "    importances_rf_base, feature_importances_rf_base = calculate_feature_importances(rf_base, feature_names, output=False)\n",
    "\n",
    "\n",
    "    ## *Visualizations*\n",
    "\n",
    "    ## Feature importances\n",
    "\n",
    "    # adapting for each model\n",
    "    importances = importances_rf_base\n",
    "    features = feature_names\n",
    "\n",
    "    # list of x locations for plotting\n",
    "    x_values = list(range(len(importances)))\n",
    "    # importance in percentages\n",
    "    importances_percent = [element*100 for element in importances]\n",
    "    # Make a bar chart\n",
    "    plt.figure(figsize=(17,5))\n",
    "    plt.bar(x_values, importances_percent, orientation = 'vertical', color='darkblue', align='center')\n",
    "    # Tick Labels for x axis\n",
    "    plt.xticks(x_values, features, rotation = 'vertical')\n",
    "    if d==0:\n",
    "        plt.xlim(-1,91)\n",
    "    else:\n",
    "        plt.xlim(-1, 92)\n",
    "        # Axis labels and title\n",
    "    plt.ylabel('Einfluss in %'); plt.xlabel('Merkmal'); plt.title('Einfluss der Merkmale auf die Vorhersage - ' + e)\n",
    "    #plt.ylabel('Importance in %'); plt.xlabel('Feature'); plt.title('Feature Importances - ' + e);\n",
    "\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_feature_importances.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "    # some seperate plots\n",
    "    if d in t: \n",
    "        # *Feature importances*\n",
    "        # list of x locations for plotting\n",
    "        x_values = list(range(len(importances)))\n",
    "        # importance in percentages\n",
    "        importances_percent = [element*100 for element in importances]\n",
    "        # Make a bar chart\n",
    "        plt.figure(figsize=(17,5))\n",
    "        plt.bar(x_values, importances_percent, orientation = 'vertical', color='darkblue', align='center')\n",
    "        # Tick Labels for x axis\n",
    "        plt.xticks(x_values, features, rotation = 'vertical')\n",
    "        plt.xlim(-1, 92)\n",
    "        plt.ylim(0, 12)\n",
    "        # Axis labels and title\n",
    "        plt.ylabel('Einfluss in %'); plt.xlabel('Merkmal'); plt.title('Einfluss der Merkmale auf die Vorhersage - ' + e)\n",
    "        #plt.ylabel('Importance in %'); plt.xlabel('Feature'); plt.title('Feature Importances - ' + e);\n",
    "        plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_feature_importances_additional.pdf',bbox_inches='tight', dpi=100)\n",
    "        plt.close()\n",
    "\n",
    "    ## Actual and predicted values\n",
    "    plot_actual_predicted_values(test_data_vis, test_labels, predictions_rf_base)\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_actual_and_predicted_values.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "    ## Autocorrelation\n",
    "    plot_acf(predictions_rf_base)\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_autocorrelation.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "    ## Precision Recall Curve\n",
    "\n",
    "    plot_prc(rf_base, test_data, test_labels, predictions_rf_base)\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_precision_recall_curve.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "    # ROC\n",
    "    plot_roc(rf_base, test_data, test_labels)\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_ROC.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "    ## Cumulative Importances   \n",
    "\n",
    "    # List of features sorted from most to least importanct \n",
    "    sorted_importances = [importance[1] for importance in feature_importances_rf_base]\n",
    "    sorted_features = [importance[0] for importance in feature_importances_rf_base]\n",
    "\n",
    "    # Cumulative importances\n",
    "    cumulative_importances = np.cumsum(sorted_importances)\n",
    "    # percentage of cumulate importance\n",
    "    cumulative_importances_percent = [element*100 for element in cumulative_importances]\n",
    "    # Make a line graph\n",
    "    f = plt.subplots(figsize=(17,5))\n",
    "    plt.plot(x_values, cumulative_importances_percent, 'darkblue', linestyle=' ', marker='.')\n",
    "    # Draw line at 95% of importance retained\n",
    "    plt.hlines(y=95, xmin=-1, xmax=len(sorted_importances), color='darkgrey', linestyles = '-')\n",
    "    plt.hlines(y=90, xmin=-1, xmax=len(sorted_importances), color='darkgrey', linestyles = '-')\n",
    "    # Format x ticks and labels\n",
    "    plt.xticks(x_values, sorted_features, rotation = 'vertical')\n",
    "    if d==0:\n",
    "        plt.xlim(-1, 91)\n",
    "    else:\n",
    "        plt.xlim(-1, 92)\n",
    "    # Axis labels and title\n",
    "    plt.xlabel('Merkmal'); plt.ylabel('Kumulierter Einfluss in %');\n",
    "    plt.title('Kumulierter Einfluss der Merkmale - '+e)\n",
    "    #plt.xlabel('Feature'); plt.ylabel('Cumulative Importance in %');\n",
    "    #plt.title('Cumulative Importances - '+e)\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_cumulative_importances.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "    # Find number of features for cumulative importance of 95%\n",
    "    # Add 1 because Python is zero-indexed\n",
    "    cumulative_importance_95 = (np.where(cumulative_importances > 0.95) [0][0]+1)\n",
    "    print('Number of features for 95% importance: ',\n",
    "             cumulative_importance_95)\n",
    "    # Find number of features for cumulative importance of 90%\n",
    "    # Add 1 because Python is zero-indexed\n",
    "    cumulative_importance_90 = (np.where(cumulative_importances > 0.90) [0][0]+1)\n",
    "    print('Number of features for 90% importance: ',\n",
    "             cumulative_importance_90)\n",
    "\n",
    "\n",
    "    ## *Confusion Matrix*\n",
    "\n",
    "    print(confusion_matrix(test_labels, predictions_rf_base))\n",
    "    # Plot confusion matrix\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "    #titles_options = [(\"Konfusionsmatrix ohne Normalisierung\", None),\n",
    "    #                     (\"Normalisierte Konfusionsmatrix\", 'true')]\n",
    "    titles_options = [(\"Confusion matrix without normalization\", None),\n",
    "                         (\"Normalized confusion matrix\", 'true')]\n",
    "    for title, normalize in titles_options:\n",
    "        disp = plot_confusion_matrix(rf_base, test_data, test_labels,\n",
    "                                        cmap=plt.cm.Blues,\n",
    "                                        normalize=normalize)\n",
    "        disp.ax_.set_title(title)\n",
    "        plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_'+title+'.pdf',bbox_inches='tight', dpi=100)\n",
    "        plt.close()\n",
    "    plt.close()\n",
    "    \n",
    "    rf_base.get_params()\n",
    "\n",
    "\n",
    "    ## *Save results to csv*\n",
    "\n",
    "    # Format for saving importances\n",
    "    header = []\n",
    "    for k in ['1st Feature', '1st Importance', '2nd Feature', '2nd Importane', '3rd Feature', '3rd Importance']:\n",
    "        header.append(k)\n",
    "\n",
    "    for i in range (4,95):\n",
    "        s = str(i)\n",
    "        k = s+'th'\n",
    "        header.append(k+' Feature')\n",
    "        header.append(k+' Importance')\n",
    "\n",
    "    header.insert(0, 'Timestep')\n",
    "\n",
    "    lst1 = [k for (k, v) in feature_importances_rf_base]\n",
    "    lst2 = [v for (k, v) in feature_importances_rf_base]\n",
    "\n",
    "    line = [x for y in zip(lst1, lst2) for x in y]\n",
    "    line.insert(0, e)\n",
    "\n",
    "    # Save\n",
    "    if d==1:\n",
    "            # Creating csv file with results for model\n",
    "            with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_results.csv', 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['Timestep','Accuracy - Training Set', 'Accuracy - Test Set','Precision', 'Recall','F1-Score', 'Matthews Correlation Coefficient', '95%', '90%'])\n",
    "                writer.writerow([e, accuracy_train_rf_base, accuracy_rf_base, precision_rf_base, recall_rf_base, f1_rf_base, mcc_rf_base, cumulative_importance_95, cumulative_importance_90])\n",
    "            # Creating csv file with results of importances\n",
    "            with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_feature_importances.csv', 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(header)\n",
    "                writer.writerow(line)\n",
    "    else:    \n",
    "            # Appending results for model to csv file\n",
    "            with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_results.csv', 'a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([e, accuracy_train_rf_base, accuracy_rf_base, precision_rf_base, recall_rf_base, f1_rf_base, mcc_rf_base, cumulative_importance_95, cumulative_importance_90])\n",
    "            # Appending results of importances to csv file\n",
    "            with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_feature_importances.csv', 'a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(line)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### MODEL WITH TUNED HYPERPARAMETER \n",
    "\n",
    "    # Instantiate model with tuned hyperparameter\n",
    "    rf_hyp = RandomForestClassifier(n_estimators = 100, max_depth = 60, min_samples_split = 5, min_samples_leaf = 1, random_state = 42)\n",
    "    model_name = 'hyp'\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_hyp.fit(train_data, train_labels)\n",
    "\n",
    "    # Calculate accuracy on the training set\n",
    "    accuracy_train_rf_hyp = rf_hyp.score(train_data, train_labels)\n",
    "\n",
    "    # Make predictions on test set and calculate metrics\n",
    "    predictions_rf_hyp, metrics_rf_hyp, accuracy_rf_hyp, precision_rf_hyp, recall_rf_hyp, f1_rf_hyp, mcc_rf_hyp = predict_with_model(rf_hyp, test_data, test_labels)\n",
    "\n",
    "    # Calculate feature importances\n",
    "    importances_rf_hyp, feature_importances_rf_hyp = calculate_feature_importances(rf_hyp, feature_names, output=False)\n",
    "\n",
    "\n",
    "    ## *Visualizations*\n",
    "\n",
    "    ## Feature importances\n",
    "\n",
    "    # adapting for each model\n",
    "    importances = importances_rf_hyp\n",
    "    features = feature_names\n",
    "\n",
    "    # list of x locations for plotting\n",
    "    x_values = list(range(len(importances)))\n",
    "    # importance in percentages\n",
    "    importances_percent = [element*100 for element in importances]\n",
    "    # Make a bar chart\n",
    "    plt.figure(figsize=(17,5))\n",
    "    plt.bar(x_values, importances_percent, orientation = 'vertical', color='darkblue', align='center')\n",
    "    # Tick Labels for x axis\n",
    "    plt.xticks(x_values, features, rotation = 'vertical')\n",
    "    if d==0:\n",
    "        plt.xlim(-1,91)\n",
    "    else:\n",
    "        plt.xlim(-1, 92)\n",
    "        # Axis labels and title\n",
    "    plt.ylabel('Einfluss in %'); plt.xlabel('Merkmal'); plt.title('Einfluss der Merkmale auf die Vorhersage - ' + e)\n",
    "    #plt.ylabel('Importance in %'); plt.xlabel('Feature'); plt.title('Feature Importances - ' + e);\n",
    "\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_feature_importances.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "    # some seperate plots\n",
    "    if d in t:\n",
    "       # *Feature importances*\n",
    "        # list of x locations for plotting\n",
    "        x_values = list(range(len(importances)))\n",
    "        # importance in percentages\n",
    "        importances_percent = [element*100 for element in importances]\n",
    "        # Make a bar chart\n",
    "        plt.figure(figsize=(17,5))\n",
    "        plt.bar(x_values, importances_percent, orientation = 'vertical', color='darkblue', align='center')\n",
    "        # Tick Labels for x axis\n",
    "        plt.xticks(x_values, features, rotation = 'vertical')\n",
    "        plt.xlim(-1, 92)\n",
    "        plt.ylim(0, 12)\n",
    "        # Axis labels and title\n",
    "        plt.ylabel('Einfluss in %'); plt.xlabel('Merkmal'); plt.title('Einfluss der Merkmale auf die Vorhersage - ' + e)\n",
    "        #plt.ylabel('Importance in %'); plt.xlabel('Feature'); plt.title('Feature Importances - ' + e);\n",
    "        plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_feature_importances_additional.pdf',bbox_inches='tight', dpi=100)\n",
    "        plt.close()\n",
    "    plt.close()\n",
    "\n",
    "    ## Actual and predicted values\n",
    "    plot_actual_predicted_values(test_data_vis, test_labels, predictions_rf_hyp)\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_actual_and_predicted_values.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "    ## Autocorrelation\n",
    "    plot_acf(predictions_rf_hyp)\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_autocorrelation.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "    ## Precision Recall Curve\n",
    "\n",
    "    plot_prc(rf_hyp, test_data, test_labels, predictions_rf_hyp)\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_precision_recall_curve.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "    ## ROC\n",
    "    plot_roc(rf_hyp, test_data, test_labels)\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_ROC.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "    ## Cumulative Importances    \n",
    "\n",
    "    # List of features sorted from most to least importance \n",
    "    sorted_importances = [importance[1] for importance in feature_importances_rf_hyp]\n",
    "    sorted_features = [importance[0] for importance in feature_importances_rf_hyp]\n",
    "\n",
    "    # Cumulative importances\n",
    "    cumulative_importances = np.cumsum(sorted_importances)\n",
    "    # percentage of cumulate importance\n",
    "    cumulative_importances_percent = [element*100 for element in cumulative_importances]\n",
    "    # Make a line graph\n",
    "    f = plt.subplots(figsize=(17,5))\n",
    "    plt.plot(x_values, cumulative_importances_percent, 'darkblue', linestyle=' ', marker='.')\n",
    "    # Draw line at 95% of importance retained\n",
    "    plt.hlines(y=95, xmin=-1, xmax=len(sorted_importances), color='darkgrey', linestyles = '-')\n",
    "    plt.hlines(y=90, xmin=-1, xmax=len(sorted_importances), color='darkgrey', linestyles = '-')\n",
    "    # Format x ticks and labels\n",
    "    plt.xticks(x_values, sorted_features, rotation = 'vertical')\n",
    "    if d==0:\n",
    "        plt.xlim(-1, 91)\n",
    "    else:\n",
    "        plt.xlim(-1, 92)\n",
    "    # Axis labels and title\n",
    "    plt.xlabel('Merkmal'); plt.ylabel('Kumulierter Einfluss in %');\n",
    "    plt.title('Kumulierter Einfluss der Merkmale - '+e)\n",
    "    #plt.xlabel('Feature'); plt.ylabel('Cumulative Importance in %');\n",
    "    #plt.title('Cumulative Importances - '+e)\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_cumulative_importances.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "    # Find number of features for cumulative importance of 95%\n",
    "    # Add 1 because Python is zero-indexed\n",
    "    cumulative_importance_95 = (np.where(cumulative_importances > 0.95) [0][0]+1)\n",
    "    print('Number of features for 95% importance: ',\n",
    "             cumulative_importance_95)\n",
    "    # Find number of features for cumulative importance of 90%\n",
    "    # Add 1 because Python is zero-indexed\n",
    "    cumulative_importance_90 = (np.where(cumulative_importances > 0.90) [0][0]+1)\n",
    "    print('Number of features for 90% importance: ',\n",
    "             cumulative_importance_90)\n",
    "\n",
    "\n",
    "    ## *Confusion Matrix*\n",
    "\n",
    "    print(confusion_matrix(test_labels, predictions_rf_hyp))\n",
    "    # Plot confusion matrix\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "    #titles_options = [(\"Konfusionsmatrix ohne Normalisierung\", None),\n",
    "    #                     (\"Normalisierte Konfusionsmatrix\", 'true')]\n",
    "    titles_options = [(\"Confusion matrix without normalization\", None),\n",
    "                         (\"Normalized confusion matrix\", 'true')]\n",
    "    for title, normalize in titles_options:\n",
    "        disp = plot_confusion_matrix(rf_hyp, test_data, test_labels,\n",
    "                                        cmap=plt.cm.Blues,\n",
    "                                        normalize=normalize)\n",
    "        disp.ax_.set_title(title)\n",
    "        plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_'+title+'.pdf',bbox_inches='tight', dpi=100)\n",
    "        plt.close()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    ## *Save results*\n",
    "\n",
    "    # Format for saving importances\n",
    "    header = []\n",
    "    for k in ['1st Feature', '1st Importance', '2nd Feature', '2nd Importane', '3rd Feature', '3rd Importance']:\n",
    "        header.append(k)\n",
    "\n",
    "    for i in range (4,95):\n",
    "        s = str(i)\n",
    "        k = s+'th'\n",
    "        header.append(k+' Feature')\n",
    "        header.append(k+' Importance')\n",
    "\n",
    "    header.insert(0, 'Timestep')\n",
    "\n",
    "    lst1 = [k for (k, v) in feature_importances_rf_hyp]\n",
    "    lst2 = [v for (k, v) in feature_importances_rf_hyp]\n",
    "\n",
    "    line = [x for y in zip(lst1, lst2) for x in y]\n",
    "    line.insert(0, e)\n",
    "\n",
    "    # Save\n",
    "    if d==1:\n",
    "            # Creating csv file with results\n",
    "            with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_results.csv', 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['Timestep','Accuracy - Training Set', 'Accuracy - Test Set','Precision', 'Recall','F1-Score', 'Matthews Correlation Coefficient', '95%', '90%'])\n",
    "                writer.writerow([e, accuracy_train_rf_hyp, accuracy_rf_hyp, precision_rf_hyp, recall_rf_hyp, f1_rf_hyp, mcc_rf_hyp, cumulative_importance_95, cumulative_importance_90])\n",
    "            # Creating csv file with results of importances\n",
    "            with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_feature_importances.csv', 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(header)\n",
    "                writer.writerow(line)\n",
    "    else:    \n",
    "            # Appending results for model to csv file\n",
    "            with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_results.csv', 'a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([e, accuracy_train_rf_hyp, accuracy_rf_hyp, precision_rf_hyp, recall_rf_hyp, f1_rf_hyp, mcc_rf_hyp, cumulative_importance_95, cumulative_importance_90])\n",
    "            # Appending results of importances to csv file\n",
    "            with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_feature_importances.csv', 'a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(line)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### MODEL WITH THREE MOST IMPORTANT FEATURES\n",
    "\n",
    "    # Instantiate model with tuned hyperparameter\n",
    "    rf_three = RandomForestClassifier(n_estimators = 100, random_state=42)\n",
    "    model_name = 'three_most_important_features'\n",
    "\n",
    "    # Extract the three most important features in order of importance out of tuned hyperparameter rf\n",
    "    sorted_features = [importance[0] for importance in feature_importances_rf_hyp]\n",
    "\n",
    "    # Create dataset\n",
    "    three_indices = [data_list.index(sorted_features[0]), data_list.index(sorted_features[1]), data_list.index(sorted_features[2])]\n",
    "    train_three = train_data[:, three_indices]\n",
    "    test_three = test_data[:, three_indices]\n",
    "    three_feature_names = [sorted_features[0], sorted_features[1], sorted_features[2]]\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_three.fit(train_three, train_labels)\n",
    "\n",
    "    # Calculate accuracy on the training set\n",
    "    accuracy_train_rf_three = rf_three.score(train_three, train_labels)\n",
    "\n",
    "    # Make predictions on test set and calculate metrics\n",
    "    predictions_rf_three, metrics_rf_three, accuracy_rf_three, precision_rf_three, recall_rf_three, f1_rf_three, mcc_rf_three = predict_with_model(rf_three, test_three, test_labels)\n",
    "\n",
    "    # Calculate feature importances\n",
    "    importances_rf_three, feature_importances_rf_three = calculate_feature_importances(rf_three, three_feature_names, output=False)\n",
    "\n",
    "\n",
    "    ## *Visualization*\n",
    "\n",
    "    ## Feature importances\n",
    "\n",
    "    # adapting for each model\n",
    "    importances = importances_rf_three\n",
    "    features = three_feature_names\n",
    "\n",
    "    # list of x locations for plotting\n",
    "    x_values = list(range(len(importances)))\n",
    "    importances_percent = [element*100 for element in importances]\n",
    "    # Make a bar chart\n",
    "    plt.bar(x_values, importances_percent, orientation = 'vertical', color='darkblue')\n",
    "    # Tick Labels for x axis\n",
    "    plt.xticks(x_values, features, rotation = 'vertical')\n",
    "    # Axis labels and title\n",
    "    plt.ylabel('Einfluss in %'); plt.xlabel('Merkmal'); plt.title('Einfluss der Merkmale auf die Vorhersage - '+e);\n",
    "    #plt.ylabel('Importance in %'); plt.xlabel('Feature'); plt.title('Feature Importances - '+e);\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_feature_importances.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "    ## Actual and predicted values\n",
    "    plot_actual_predicted_values(test_data_vis, test_labels, predictions_rf_three)\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_actual_and_predicted_values.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    ## *Confusion Matrix*\n",
    "\n",
    "    print(confusion_matrix(test_labels, predictions_rf_three))\n",
    "    # Plot confusion matrix\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    #titles_options = [(\"Konfusionsmatrix ohne Normalisierung\", None),\n",
    "    #                     (\"Normalisierte Konfusionsmatrix\", 'true')]\n",
    "    titles_options = [(\"Confusion matrix without normalization\", None),\n",
    "                         (\"Normalized confusion matrix\", 'true')]\n",
    "    for title, normalize in titles_options:\n",
    "        disp = plot_confusion_matrix(rf_three, test_three, test_labels,\n",
    "                                        cmap=plt.cm.Blues,\n",
    "                                        normalize=normalize)\n",
    "        disp.ax_.set_title(title)\n",
    "        plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_'+title+'.pdf',bbox_inches='tight', dpi=100)\n",
    "        plt.close()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    ## *Save results*\n",
    "\n",
    "    if d==1:\n",
    "            # Creating csv file with results\n",
    "            with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_results.csv', 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['Timestep','Accuracy - Training Set', 'Accuracy - Test Set','Precision', 'Recall','F1-Score', 'Matthews Correlation Coefficient'])\n",
    "                writer.writerow([e, accuracy_train_rf_three, accuracy_rf_three, precision_rf_three, recall_rf_three, f1_rf_three, mcc_rf_three])\n",
    "    else:    \n",
    "            # Appending results for model to csv file\n",
    "            with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_results.csv', 'a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([e, accuracy_train_rf_three, accuracy_rf_three, precision_rf_three, recall_rf_three, f1_rf_three, mcc_rf_three])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### MODEL WITH FIVE MOST IMPORTANT FEATURES\n",
    "\n",
    "    # Instantiate model with tuned hyperparameter\n",
    "    rf_five = RandomForestClassifier(n_estimators = 100, random_state=42)\n",
    "    model_name = 'five_most_important_features'\n",
    "\n",
    "    # Extract the five most important features in order of importance out of tuned hyperparameter rf\n",
    "    sorted_features = [importance[0] for importance in feature_importances_rf_hyp]\n",
    "\n",
    "    # Create data set\n",
    "    five_indices = [data_list.index(sorted_features[0]), data_list.index(sorted_features[1]), data_list.index(sorted_features[2]), data_list.index(sorted_features[3]), data_list.index(sorted_features[4])]\n",
    "    train_five = train_data[:, five_indices]\n",
    "    test_five = test_data[:, five_indices]\n",
    "    five_feature_names = [sorted_features[0], sorted_features[1], sorted_features[2], sorted_features[3], sorted_features[4]]\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_five.fit(train_five, train_labels)\n",
    "\n",
    "    # Calculate accuracy on the training set\n",
    "    accuracy_train_rf_five = rf_five.score(train_five, train_labels)\n",
    "\n",
    "    # Make predictions on test set and calculate metrics\n",
    "    predictions_rf_five, metrics_rf_five, accuracy_rf_five, precision_rf_five, recall_rf_five, f1_rf_five, mcc_rf_five = predict_with_model(rf_five, test_five, test_labels)\n",
    "\n",
    "    # Calculate feature importances\n",
    "    importances_rf_five, feature_importances_rf_five = calculate_feature_importances(rf_five, five_feature_names, output=False)\n",
    "\n",
    "\n",
    "    ## *Visualization*\n",
    "\n",
    "    ## Feature importances\n",
    "\n",
    "    # adapting for each model\n",
    "    importances = importances_rf_five\n",
    "    features = five_feature_names\n",
    "\n",
    "    # list of x locations for plotting\n",
    "    x_values = list(range(len(importances)))\n",
    "    importances_percent = [element*100 for element in importances]\n",
    "    # Make a bar chart\n",
    "    plt.bar(x_values, importances_percent, orientation = 'vertical', color='darkblue')\n",
    "    # Tick Labels for x axis\n",
    "    plt.xticks(x_values, features, rotation = 'vertical')\n",
    "    # Axis labels and title\n",
    "    plt.ylabel('Einfluss in %'); plt.xlabel('Merkmal'); plt.title('Einfluss der Merkmale auf die Vorhersage - '+e);\n",
    "    #plt.ylabel('Importance in %'); plt.xlabel('Feature'); plt.title('Feature Importances - '+e);\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_feature_importances.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "    ## Actual and predicted values\n",
    "    plot_actual_predicted_values(test_data_vis, test_labels, predictions_rf_five)\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_actual_and_predicted_values.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    ## *Confusion Matrix*\n",
    "\n",
    "    print(confusion_matrix(test_labels, predictions_rf_five))\n",
    "    # Plot confusion matrix\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    #titles_options = [(\"Konfusionsmatrix ohne Normalisierung\", None),\n",
    "    #                     (\"Normalisierte Konfusionsmatrix\", 'true')]\n",
    "    titles_options = [(\"Confusion matrix without normalization\", None),\n",
    "                         (\"Normalized confusion matrix\", 'true')]\n",
    "    for title, normalize in titles_options:\n",
    "        disp = plot_confusion_matrix(rf_five, test_five, test_labels,\n",
    "                                        cmap=plt.cm.Blues,\n",
    "                                        normalize=normalize)\n",
    "        disp.ax_.set_title(title)\n",
    "        plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_'+title+'.pdf',bbox_inches='tight', dpi=100)\n",
    "        plt.close()\n",
    "    plt.close()\n",
    "\n",
    "    ## *Save results*\n",
    "\n",
    "    if d==1:\n",
    "            # Creating csv file with results\n",
    "            with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_results.csv', 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['Timestep','Accuracy - Training Set', 'Accuracy - Test Set','Precision', 'Recall','F1-Score', 'Matthews Correlation Coefficient'])\n",
    "                writer.writerow([e, accuracy_train_rf_five, accuracy_rf_five, precision_rf_five, recall_rf_five, f1_rf_five, mcc_rf_five])\n",
    "    else:    \n",
    "            # Appending results for model to csv file\n",
    "            with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_results.csv', 'a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([e, accuracy_train_rf_five, accuracy_rf_five, precision_rf_five, recall_rf_five, f1_rf_five, mcc_rf_five])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_base.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73137, 92)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24380, 92)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
