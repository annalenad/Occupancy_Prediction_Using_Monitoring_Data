{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model for Occupancy Detection in an Office Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Analytics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "## Plots\n",
    "\n",
    "# Import matplotlib and seaborn for plotting and use magic command for Jupyter Notebooks\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Set the style for plots\n",
    "plt.style.use('fivethirtyeight')\n",
    "#plt.rc(\"font\", size=14)\n",
    "import seaborn as sns\n",
    "#sns.set(style=\"white\")\n",
    "#sns.set(style=\"whitegrid\", color_codes=True)\n",
    "sns.set_theme(style='whitegrid', font='Arial', rc={'figure.figsize':(10,5),\n",
    "            'font.size':14,\n",
    "            'axes.titlesize':16,\n",
    "            'axes.labelsize':15,\n",
    "            'xtick.labelsize': 12,\n",
    "            'ytick.labelsize': 12,\n",
    "            'legend.fontsize': 13},color_codes=True)\n",
    "\n",
    "#sns.set(rc={'figure.figsize':(20, 10)})\n",
    "# Pydot is used for visualization\n",
    "import pydot\n",
    "\n",
    "\n",
    "## Machine Learning\n",
    "\n",
    "# Skicit-learn\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "# Import the model that is used - Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "# Import function to calculate accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "# Precision and recall\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "# Import autocorrelation function\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "# Import Matthews Correlation Coefficient\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "\n",
    "# CSV\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 1\n",
    "def predict_with_model(fitted_model, X_val, y_val, output=True):\n",
    "    '''\n",
    "    Function to make a prediction based on a trained model, returns metrics for classification\n",
    "    \n",
    "    Inputs: \n",
    "    fitted_model: On a training set fitted model to use for prediction \n",
    "    X_val (np.array): numpy array with feature vectors of validation (or test) data\n",
    "    y_val (np.array): numpy array with true labels of validation(or test) data\n",
    "    output (bool): if output should be printed or not, default is True\n",
    "   \n",
    "    Outputs:\n",
    "    y_pred (np.array): Prediction for feature vectors of validation (or test) data of the model\n",
    "    metrics_dict (dict): Dictionary with metrics for classification\n",
    "    accuracy (float): Accuracy of the prediction\n",
    "    precision (float): Precision of the prediction\n",
    "    recall (float): Recall of the prediction\n",
    "    f1 (float): F1-Score of the prediction\n",
    "    mcc (float): Matthews Correlation Coefficient of the prediction\n",
    "    '''  \n",
    "    \n",
    "    # Use the trained model to make predictions on the validation (or test) set\n",
    "    y_pred = fitted_model.predict(X_val)\n",
    "    \n",
    "    ## Metrics for classification\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    # Precision\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    # Recall\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    # F1-Score\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    # MCC\n",
    "    mcc = matthews_corrcoef(y_val, y_pred)\n",
    "    \n",
    "        \n",
    "    metrics_dict = {'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1,\n",
    "                    'mcc': mcc\n",
    "                   }\n",
    "    \n",
    "    if output:\n",
    "        print('Mean of true labels:', round(np.mean(y_val), 2))\n",
    "        print('Accuracy:', accuracy)\n",
    "        print('Precision:', precision)\n",
    "        print('Recall:', recall)\n",
    "        print('F1-Score:', f1)\n",
    "        print('MCC:', mcc)\n",
    "            \n",
    "    return y_pred, metrics_dict, accuracy, precision, recall, f1, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 6\n",
    "def calculate_feature_importances(model, features, output=True):\n",
    "    '''\n",
    "    Function to calculate feature importances of a random forest model\n",
    "    \n",
    "    Inputs:\n",
    "    model: on a training set fitted and on a test set tested model\n",
    "    features (lst): list containing the names of the features\n",
    "    output: print results True or False (True by default)\n",
    "    \n",
    "    Outputs:\n",
    "    importances (lst): list with all importances for the features but not sorted (same order as features in input)\n",
    "    df_feature_importances (df): Dataframe with features and their corresponding importance sorted from highest to lowest\n",
    "    '''\n",
    "    # Get numerical feature importances\n",
    "    importances = list(model.feature_importances_)\n",
    "    \n",
    "    # List of tuples with feature and importance\n",
    "    feature_importances = [(feature, round(importance, 3)) for feature, importance in zip(feature_names, importances)]\n",
    "    \n",
    "    # Sort the feature importances from highest to lowest\n",
    "    feature_importances = sorted(feature_importances, key = lambda x:\n",
    "                                x[1], reverse = True)\n",
    "    \n",
    "    if output:\n",
    "        # Print out the feature and importances\n",
    "        [print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]\n",
    "        \n",
    "    #df_feature_importances = pd.DataFrame(feature_importances, columns=['feature', 'importance'])\n",
    "    \n",
    "    return importances, feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 7\n",
    "def plot_roc(model, X_test, y_test):\n",
    "    '''\n",
    "    Function to plot Receiver Operating Curve in desired layout\n",
    "    \n",
    "    Inputs:\n",
    "    model: on a training set fitted and on a test set tested model\n",
    "    X_test (np.array): numpy array with feature vectors of test data\n",
    "    y_test (np.array): numpy array with true labels of test data\n",
    "    \n",
    "    Outputs:\n",
    "    plot of ROC\n",
    "    \n",
    "    '''\n",
    "    model_roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label= 'Random Forest '+model_name+' (area = %0.2f)' % model_roc_auc, color='darkblue')\n",
    "    plt.plot([0,1], [0,1], 'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic - '+e)\n",
    "    plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 8\n",
    "def plot_prc(model, X_test, y_test, y_pred):\n",
    "    '''\n",
    "    Function to plot Receiver Operating Curve in desired layout\n",
    "    \n",
    "    Inputs:\n",
    "    model: on a training set fitted and on a test set tested model\n",
    "    X_test (np.array): numpy array with feature vectors of test data\n",
    "    y_test (np.array): numpy array with true labels of test data\n",
    "    y_pred (np.array): numpy array with predictions of test data\n",
    "    \n",
    "    Outputs:\n",
    "    plot of Precision Recall Curve\n",
    "    '''\n",
    "    \n",
    "    average_precision = average_precision_score(y_test, y_pred)\n",
    "    print('Average precision-recall score: {0:0.4f}'.format(average_precision))\n",
    "    \n",
    "    disp = plot_precision_recall_curve(model, X_test, y_test, color='darkblue')\n",
    "    disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                      'AP={0:0.4f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 8\n",
    "def plot_actual_predicted_values(X_test_vis, y_test, y_pred):\n",
    "    '''\n",
    "    Function to plot actual and predicted values in desired layout \n",
    "    \n",
    "    Inputs:\n",
    "    model: on a training set fitted and on a test set tested model\n",
    "    X_test_vis (np.array): numpy array with feature vectors of test data \n",
    "                            including columns of month, day, year, hour, minute, second (not one-hot encoded)\n",
    "    y_test (np.array): numpy array with true labels of test data\n",
    "    y_pred (np.array): numpy array with predictions of test data\n",
    "    \n",
    "    Outputs:\n",
    "    plot of actual an predicted values\n",
    "    \n",
    "    '''\n",
    "    # Dates of testing data/predictions\n",
    "    months = X_test_vis[:, data_list.index('Month')]\n",
    "    days = X_test_vis[:, data_list.index('Day')]\n",
    "    years = X_test_vis[:, data_list.index('Year')]\n",
    "    hours = X_test_vis[:, data_list.index('Hour')]\n",
    "    minutes = X_test_vis[:, data_list.index('Minute')]\n",
    "    seconds = X_test_vis[:, data_list.index('Second')]\n",
    "    \n",
    "    # List and then convert to datetime object\n",
    "    test_dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) + ' ' + str(int(hour)) + ':' + str(int(minute)) + ':' + str(int(second)) \n",
    "                                                                                      for year, month, day, hour, minute, second in zip(years, months, days, hours, minutes, seconds)]\n",
    "\n",
    "    test_dates = [datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S') for date in test_dates]\n",
    "\n",
    "    # Dataframe with true values and dates\n",
    "    true_data = pd.DataFrame(data = {'date': test_dates, 'actual': y_test})\n",
    "\n",
    "    # Dataframe with predictions and dates\n",
    "    predictions_data = pd.DataFrame(data = {'date': test_dates, 'prediction': y_pred})\n",
    "    \n",
    "    # Plot the actual values\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.plot(true_data['date'], true_data['actual'],'darkblue', label = 'tatsächlicher Wert')\n",
    "    #plt.plot(true_data['date'], true_data['actual'],'darkblue', label = 'actual')\n",
    "    # Plot the predicted values\n",
    "    plt.plot(predictions_data['date'], predictions_data['prediction'], 'ro', label = 'vorhergesagter Wert')\n",
    "    #plt.plot(predictions_data['date'], predictions_data['prediction'], 'ro', label = 'prediction')\n",
    "    plt.xticks(rotation = '60');\n",
    "    plt.yticks([0,1])\n",
    "    plt.xlim(13330, 13515)\n",
    "    plt.legend()\n",
    "    # Graph labels\n",
    "    plt.xlabel('Datum'); plt.ylabel('Belegung'); plt.title('Tatsächliche und vorhergesagte Werte - '+e);\n",
    "    #plt.xlabel('Date'); plt.ylabel('Occupancy'); plt.title('Actual and Predicted Values');\n",
    "    # Dataframe with test values and dates\n",
    "    testing_data = pd.DataFrame(data = {'date': test_dates, 'actual': y_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = room number\n",
    "a = 'E07'\n",
    "# b = number of lags as input\n",
    "b = '5'\n",
    "# c = number of last timestep to predict (not used with prediction of t)\n",
    "#c = 1\n",
    "# t = timesteps for seperate plots (not necessary with prediction of t)\n",
    "t = [6, 12, 18, 24, 30, 36]\n",
    "# d = number of timestep to predict\n",
    "d = 0\n",
    "# e = timestep in format 't+x' as string\n",
    "e = 't'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data and set index\n",
    "raw_data = pd.read_csv(\"\\Pre-Processing\\data_E07_input_5_output_144.txt\", parse_dates=True)\n",
    "data = raw_data.copy()\n",
    "data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "data = data.set_index('DateTime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns for Second\n",
    "data = data.drop('Second_0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns of future timestamps that should not be used as input for this model\n",
    "if d==0:\n",
    "    for i in range(1,145):\n",
    "        v = 't+'+str(i)\n",
    "        data = data.drop(v, axis = 1)\n",
    "else:\n",
    "    for i in range(d+1,145):\n",
    "        v = 't+'+str(i)\n",
    "        data = data.drop(v, axis = 1)\n",
    "\n",
    "    for i in range(1, d):\n",
    "        v = 't+'+str(i)\n",
    "        data = data.drop(v, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns with year, month, day and weekday name at the end of the dataset for later use of visualization \n",
    "data['Year'] = data.index.year\n",
    "data['Month'] = data.index.month\n",
    "data['Day'] = data.index.day\n",
    "data['Weekday Name'] = data.index.day_name()\n",
    "data['Hour'] = data.index.hour\n",
    "data['Minute'] = data.index.minute\n",
    "data['Second'] = data.index.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy to convert to arrays\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(data[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the labels from the data\n",
    "# axis 1 refers to the columns\n",
    "data = data.drop(e, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data names for later use\n",
    "data_list = list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save copy before transforming to numpy array\n",
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the one hot encoded data\n",
    "# lags should not be used in this model\n",
    "feature_names = [i for i in data_list if i not in ['t-5', 't-4', 't-3', 't-2', 't-1',\n",
    "                                                   'Year', 'Month','Day','Hour','Minute','Second','Weekday Name']]\n",
    "indices = [data_list.index(feature_names[x]) for x in range(0,len(feature_names))]\n",
    "data_to_use = data[:, indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets using scikit-learn \n",
    "# 25% so that approximately the last 6 months are covered in the test set\n",
    "# shuffle = False because of time series data\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data_to_use, labels, test_size = 0.25, shuffle=False)\n",
    "train_data_vis, test_data_vis, train_labels_vis, test_labels_vis = train_test_split(data, labels, test_size = 0.25, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (73137, 86)\n",
      "Training Labels Shape: (73137,)\n",
      "Testing Data Shape: (24380, 86)\n",
      "Testing Labels Shape: (24380,)\n",
      "Training Data Shape: (73137, 98)\n",
      "Training Labels Shape: (73137,)\n",
      "Testing Data Shape: (24380, 98)\n",
      "Testing Labels Shape: (24380,)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes of data sets\n",
    "print('Training Data Shape:', train_data.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Data Shape:', test_data.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)\n",
    "\n",
    "print('Training Data Shape:', train_data_vis.shape)\n",
    "print('Training Labels Shape:', train_labels_vis.shape)\n",
    "print('Testing Data Shape:', test_data_vis.shape)\n",
    "print('Testing Labels Shape:', test_labels_vis.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Modeling -  Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate base model with 100 decision trees\n",
    "rf_base = RandomForestClassifier(n_estimators = 100, random_state=42)\n",
    "# model name\n",
    "model_name = 'base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on training data\n",
    "rf_base.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on the training set\n",
    "accuracy_train_rf_base = rf_base.score(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9112797374897457\n",
      "Precision: 0.796313651983755\n",
      "Recall: 0.6278325123152709\n",
      "F1-Score: 0.7021071477757885\n",
      "MCC: 0.6571891233690857\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set and calculate metrics\n",
    "predictions_rf_base, metrics_rf_base, accuracy_rf_base, precision_rf_base, recall_rf_base, f1_rf_base, mcc_rf_base = predict_with_model(rf_base, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate variable importances\n",
    "importances_rf_base, feature_importances_rf_base = calculate_feature_importances(rf_base, feature_names, output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *Variable importances*\n",
    "\n",
    "# adapting for each model\n",
    "importances = importances_rf_base\n",
    "features = feature_names\n",
    "\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# importance in percentages\n",
    "importances_percent = [element*100 for element in importances]\n",
    "# Make a bar chart\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.bar(x_values, importances_percent, orientation = 'vertical', color='darkblue', align='center')\n",
    "# Tick Labels for x axis\n",
    "plt.xticks(x_values, features, rotation = 'vertical')\n",
    "if d==0:\n",
    "    plt.xlim(-1,86)\n",
    "else:\n",
    "    plt.xlim(-1, 92)\n",
    "    # Axis labels and title\n",
    "plt.ylabel('Einfluss in %'); plt.xlabel('Merkmal'); plt.title('Einfluss der Merkmale auf die Vorhersage - ' + e)\n",
    "#plt.ylabel('Importance in %'); plt.xlabel('Feature'); plt.title('Feature Importances - ' + e);\n",
    "\n",
    "plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_feature_importances.pdf',bbox_inches='tight', dpi=100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual and predicted values\n",
    "plot_actual_predicted_values(test_data_vis, test_labels, predictions_rf_base)\n",
    "plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_actual_and_predicted_values.pdf',bbox_inches='tight', dpi=100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *Autocorrelation*\n",
    "plot_acf(predictions_rf_base)\n",
    "plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_autocorrelation.pdf',bbox_inches='tight', dpi=100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19668   652]\n",
      " [ 1511  2549]]\n"
     ]
    }
   ],
   "source": [
    "# *Confusion Matrix*\n",
    "\n",
    "print(confusion_matrix(test_labels, predictions_rf_base))\n",
    "# Plot confusion matrix\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "#titles_options = [(\"Konfusionsmatrix ohne Normalisierung\", None),\n",
    "#                     (\"Normalisierte Konfusionsmatrix\", 'true')]\n",
    "titles_options = [(\"Confusion matrix without normalization\", None),\n",
    "                     (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(rf_base, test_data, test_labels,\n",
    "                                    cmap=plt.cm.Blues,\n",
    "                                    normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "    #plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_'+title+'.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_'+title+'.svg',bbox_inches='tight', dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.5619\n"
     ]
    }
   ],
   "source": [
    "# *Precision Recall Curve*\n",
    "\n",
    "plot_prc(rf_base, test_data, test_labels, predictions_rf_base)\n",
    "plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_precision_recall_curve.pdf',bbox_inches='tight', dpi=100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "plot_roc(rf_base, test_data, test_labels)\n",
    "plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_ROC.pdf',bbox_inches='tight', dpi=100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *Cumulative Importances*    \n",
    "\n",
    "# List of features sorted from most to least importanct \n",
    "sorted_importances = [importance[1] for importance in feature_importances_rf_base]\n",
    "sorted_features = [importance[0] for importance in feature_importances_rf_base]\n",
    "\n",
    "# Cumulative importances\n",
    "cumulative_importances = np.cumsum(sorted_importances)\n",
    "# percentage of cumulate importance\n",
    "cumulative_importances_percent = [element*100 for element in cumulative_importances]\n",
    "# Make a line graph\n",
    "f = plt.subplots(figsize=(17,5))\n",
    "plt.plot(x_values, cumulative_importances_percent, 'darkblue', linestyle=' ', marker='.')\n",
    "# Draw line at 95% of importance retained\n",
    "plt.hlines(y=95, xmin=-1, xmax=len(sorted_importances), color='darkgrey', linestyles = '-')\n",
    "plt.hlines(y=90, xmin=-1, xmax=len(sorted_importances), color='darkgrey', linestyles = '-')\n",
    "# Format x ticks and labels\n",
    "plt.xticks(x_values, sorted_features, rotation = 'vertical')\n",
    "if d==0:\n",
    "    plt.xlim(-1, 86)\n",
    "else:\n",
    "    plt.xlim(-1, 92)\n",
    "# Axis labels and title\n",
    "plt.xlabel('Merkmal'); plt.ylabel('Kumulierter Einfluss in %');\n",
    "plt.title('Kumulierter Einfluss der Merkmale - '+e)\n",
    "#plt.xlabel('Feature'); plt.ylabel('Cumulative Importance in %');\n",
    "#plt.title('Cumulative Importances - '+e)\n",
    "plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_cumulative_importances.pdf',bbox_inches='tight', dpi=100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features for 95% importance:  67\n",
      "Number of features for 90% importance:  55\n"
     ]
    }
   ],
   "source": [
    "# Find number of features for cumulative importance of 95%\n",
    "# Add 1 because Python is zero-indexed\n",
    "cumulative_importance_95 = (np.where(cumulative_importances > 0.95) [0][0]+1)\n",
    "print('Number of features for 95% importance: ',\n",
    "         cumulative_importance_95)\n",
    "# Find number of features for cumulative importance of 90%\n",
    "# Add 1 because Python is zero-indexed\n",
    "cumulative_importance_90 = (np.where(cumulative_importances > 0.90) [0][0]+1)\n",
    "print('Number of features for 90% importance: ',\n",
    "         cumulative_importance_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format for saving importances\n",
    "header = []\n",
    "for k in ['1st Feature', '1st Importance', '2nd Feature', '2nd Importane', '3rd Feature', '3rd Importance']:\n",
    "    header.append(k)\n",
    "    \n",
    "for i in range (4,95):\n",
    "    s = str(i)\n",
    "    k = s+'th'\n",
    "    header.append(k+' Feature')\n",
    "    header.append(k+' Importance')\n",
    "\n",
    "header.insert(0, 'Timestep')\n",
    "\n",
    "lst1 = [k for (k, v) in feature_importances_rf_base]\n",
    "lst2 = [v for (k, v) in feature_importances_rf_base]\n",
    "\n",
    "line = [x for y in zip(lst1, lst2) for x in y]\n",
    "line.insert(0, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating csv file with results for model with all variables\n",
    "with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_results.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Timestep','Accuracy - Training Set', 'Accuracy - Test Set','Precision', 'Recall','F1-Score', 'Matthews Correlation Coefficient', '95%', '90%'])\n",
    "    writer.writerow([e, accuracy_train_rf_base, accuracy_rf_base, precision_rf_base, recall_rf_base, f1_rf_base, mcc_rf_base, cumulative_importance_95, cumulative_importance_90])\n",
    "# Creating csv file with results of importances\n",
    "with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_feature_importances.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    writer.writerow(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Modeling -  Model With Tuned Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with tuned hyperparameter\n",
    "rf_hyp = RandomForestClassifier(n_estimators = 775, max_depth = 50, min_samples_split=6, min_samples_leaf=2, random_state=42)\n",
    "# model name\n",
    "model_name = 'hyp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=50, min_samples_leaf=2, min_samples_split=6,\n",
       "                       n_estimators=775, random_state=42)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on training data\n",
    "rf_hyp.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on the training set\n",
    "accuracy_train_rf_hyp = rf_hyp.score(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.9115258408531584\n",
      "Precision: 0.8035087719298246\n",
      "Recall: 0.6204433497536945\n",
      "F1-Score: 0.7002084781097985\n",
      "MCC: 0.6567865279279664\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set and calculate metrics\n",
    "predictions_rf_hyp, metrics_rf_hyp, accuracy_rf_hyp, precision_rf_hyp, recall_rf_hyp, f1_rf_hyp, mcc_rf_hyp = predict_with_model(rf_hyp, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable importances\n",
    "importances_rf_hyp, feature_importances_rf_hyp = calculate_feature_importances(rf_hyp, feature_names, output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *Variable importances*\n",
    "\n",
    "# adapting for each model\n",
    "importances = importances_rf_hyp\n",
    "features = feature_names\n",
    "\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# importance in percentages\n",
    "importances_percent = [element*100 for element in importances]\n",
    "# Make a bar chart\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.bar(x_values, importances_percent, orientation = 'vertical', color='darkblue', align='center')\n",
    "# Tick Labels for x axis\n",
    "plt.xticks(x_values, features, rotation = 'vertical')\n",
    "if d==0:\n",
    "    plt.xlim(-1,86)\n",
    "else:\n",
    "    plt.xlim(-1, 92)\n",
    "    # Axis labels and title\n",
    "plt.ylabel('Einfluss in %'); plt.xlabel('Merkmal'); plt.title('Einfluss der Merkmale auf die Vorhersage - ' + e)\n",
    "#plt.ylabel('Importance in %'); plt.xlabel('Feature'); plt.title('Feature Importances - ' + e);\n",
    "\n",
    "plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_feature_importances.pdf',bbox_inches='tight', dpi=100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual and predicted values\n",
    "plot_actual_predicted_values(test_data_vis, test_labels, predictions_rf_hyp)\n",
    "plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_actual_and_predicted_values.pdf',bbox_inches='tight', dpi=100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *Autocorrelation*\n",
    "plot_acf(predictions_rf_hyp)\n",
    "plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_autocorrelation.pdf',bbox_inches='tight', dpi=100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19704   616]\n",
      " [ 1541  2519]]\n"
     ]
    }
   ],
   "source": [
    "# *Confusion Matrix*\n",
    "\n",
    "print(confusion_matrix(test_labels, predictions_rf_hyp))\n",
    "# Plot confusion matrix\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "#titles_options = [(\"Konfusionsmatrix ohne Normalisierung\", None),\n",
    "#                     (\"Normalisierte Konfusionsmatrix\", 'true')]\n",
    "titles_options = [(\"Confusion matrix without normalization\", None),\n",
    "                     (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(rf_hyp, test_data, test_labels,\n",
    "                                    cmap=plt.cm.Blues,\n",
    "                                    normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_'+title+'.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.5617\n"
     ]
    }
   ],
   "source": [
    "# *Precision Recall Curve*\n",
    "\n",
    "plot_prc(rf_hyp, test_data, test_labels, predictions_rf_hyp)\n",
    "plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_precision_recall_curve.pdf',bbox_inches='tight', dpi=100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "plot_roc(rf_hyp, test_data, test_labels)\n",
    "plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_ROC.pdf',bbox_inches='tight', dpi=100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *Cumulative Importances*    \n",
    "\n",
    "# List of features sorted from most to least importance \n",
    "sorted_importances = [importance[1] for importance in feature_importances_rf_hyp]\n",
    "sorted_features = [importance[0] for importance in feature_importances_rf_hyp]\n",
    "\n",
    "# Cumulative importances\n",
    "cumulative_importances = np.cumsum(sorted_importances)\n",
    "# percentage of cumulate importance\n",
    "cumulative_importances_percent = [element*100 for element in cumulative_importances]\n",
    "# Make a line graph\n",
    "f = plt.subplots(figsize=(17,5))\n",
    "plt.plot(x_values, cumulative_importances_percent, 'darkblue', linestyle=' ', marker='.')\n",
    "# Draw line at 95% of importance retained\n",
    "plt.hlines(y=95, xmin=-1, xmax=len(sorted_importances), color='darkgrey', linestyles = '-')\n",
    "plt.hlines(y=90, xmin=-1, xmax=len(sorted_importances), color='darkgrey', linestyles = '-')\n",
    "# Format x ticks and labels\n",
    "plt.xticks(x_values, sorted_features, rotation = 'vertical')\n",
    "if d==0:\n",
    "    plt.xlim(-1, 86)\n",
    "else:\n",
    "    plt.xlim(-1, 92)\n",
    "# Axis labels and title\n",
    "plt.xlabel('Merkmal'); plt.ylabel('Kumulierter Einfluss in %');\n",
    "plt.title('Kumulierter Einfluss der Merkmale - '+e)\n",
    "#plt.xlabel('Feature'); plt.ylabel('Cumulative Importance in %');\n",
    "#plt.title('Cumulative Importances - '+e)\n",
    "plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_cumulative_importances.pdf',bbox_inches='tight', dpi=100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features for 95% importance:  68\n",
      "Number of features for 90% importance:  55\n"
     ]
    }
   ],
   "source": [
    "# Find number of features for cumulative importance of 95%\n",
    "# Add 1 because Python is zero-indexed\n",
    "cumulative_importance_95 = (np.where(cumulative_importances > 0.95) [0][0]+1)\n",
    "print('Number of features for 95% importance: ',\n",
    "         cumulative_importance_95)\n",
    "# Find number of features for cumulative importance of 90%\n",
    "# Add 1 because Python is zero-indexed\n",
    "cumulative_importance_90 = (np.where(cumulative_importances > 0.90) [0][0]+1)\n",
    "print('Number of features for 90% importance: ',\n",
    "         cumulative_importance_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format for saving importances\n",
    "header = []\n",
    "for k in ['1st Feature', '1st Importance', '2nd Feature', '2nd Importane', '3rd Feature', '3rd Importance']:\n",
    "    header.append(k)\n",
    "    \n",
    "for i in range (4,95):\n",
    "    s = str(i)\n",
    "    k = s+'th'\n",
    "    header.append(k+' Feature')\n",
    "    header.append(k+' Importance')\n",
    "\n",
    "header.insert(0, 'Timestep')\n",
    "\n",
    "lst1 = [k for (k, v) in feature_importances_rf_hyp]\n",
    "lst2 = [v for (k, v) in feature_importances_rf_hyp]\n",
    "\n",
    "line = [x for y in zip(lst1, lst2) for x in y]\n",
    "line.insert(0, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating csv file with results\n",
    "with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_results.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Timestep','Accuracy - Training Set', 'Accuracy - Test Set','Precision', 'Recall','F1-Score', 'Matthews Correlation Coefficient', '95%', '90%'])\n",
    "    writer.writerow([e, accuracy_train_rf_hyp, accuracy_rf_hyp, precision_rf_hyp, recall_rf_hyp, f1_rf_hyp, mcc_rf_hyp, cumulative_importance_95, cumulative_importance_90])\n",
    "# Creating csv file with results of importances\n",
    "with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_feature_importances.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    writer.writerow(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Modeling -  Model with three most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with tuned hyperparameter\n",
    "rf_three = RandomForestClassifier(n_estimators=100, random_state=2)\n",
    "# model name\n",
    "model_name = 'three_most_important_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the three most important features in order of importance out of tuned hyperparameter rf\n",
    "sorted_features = [importance[0] for importance in feature_importances_rf_hyp]\n",
    "\n",
    "three_indices = [data_list.index(sorted_features[0]), data_list.index(sorted_features[1]), data_list.index(sorted_features[2])]\n",
    "train_three = train_data[:, three_indices]\n",
    "test_three = test_data[:, three_indices]\n",
    "\n",
    "three_feature_names = [sorted_features[0], sorted_features[1], sorted_features[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on training data\n",
    "rf_three.fit(train_three, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on the training set\n",
    "accuracy_train_rf_three = rf_three.score(train_three, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8700984413453651\n",
      "Precision: 0.6375963020030817\n",
      "Recall: 0.5096059113300493\n",
      "F1-Score: 0.5664613278576318\n",
      "MCC: 0.49544693716273486\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set and calculate metrics\n",
    "predictions_rf_three, metrics_rf_three, accuracy_rf_three, precision_rf_three, recall_rf_three, f1_rf_three, mcc_rf_three = predict_with_model(rf_three, test_three, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable importances\n",
    "importances_rf_three, feature_importances_rf_three = calculate_feature_importances(rf_three, three_feature_names, output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable importances\n",
    "\n",
    "# adapting for each model\n",
    "importances = importances_rf_three\n",
    "features = three_feature_names\n",
    "\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "importances_percent = [element*100 for element in importances]\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances_percent, orientation = 'vertical', color='darkblue')\n",
    "# Tick Labels for x axis\n",
    "plt.xticks(x_values, features, rotation = 'vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Einfluss in %'); plt.xlabel('Merkmal'); plt.title('Einfluss der Merkmale auf die Vorhersage - '+e);\n",
    "#plt.ylabel('Importance in %'); plt.xlabel('Feature'); plt.title('Feature Importances - '+e);\n",
    "plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_feature_importances.pdf',bbox_inches='tight', dpi=100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual and predicted values\n",
    "plot_actual_predicted_values(test_data_vis, test_labels, predictions_rf_three)\n",
    "plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_actual_and_predicted_values.pdf',bbox_inches='tight', dpi=100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19144  1176]\n",
      " [ 1991  2069]]\n"
     ]
    }
   ],
   "source": [
    "# *Confusion Matrix*\n",
    "\n",
    "print(confusion_matrix(test_labels, predictions_rf_three))\n",
    "# Plot confusion matrix\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "#titles_options = [(\"Konfusionsmatrix ohne Normalisierung\", None),\n",
    "#                     (\"Normalisierte Konfusionsmatrix\", 'true')]\n",
    "titles_options = [(\"Confusion matrix without normalization\", None),\n",
    "                     (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(rf_three, test_three, test_labels,\n",
    "                                    cmap=plt.cm.Blues,\n",
    "                                    normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_'+title+'.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating csv file with results\n",
    "with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_results.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Timestep','Accuracy - Training Set', 'Accuracy - Test Set','Precision', 'Recall','F1-Score', 'Matthews Correlation Coefficient'])\n",
    "    writer.writerow([e, accuracy_train_rf_three, accuracy_rf_three, precision_rf_three, recall_rf_three, f1_rf_three, mcc_rf_three])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Modeling -  Model with five most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with tuned hyperparameter\n",
    "rf_five = RandomForestClassifier(n_estimators = 100, random_state=42)\n",
    "# model name\n",
    "model_name = 'five_most_important_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the five most important features in order of importance out of tuned hyperparameter rf\n",
    "sorted_features = [importance[0] for importance in feature_importances_rf_hyp]\n",
    "\n",
    "five_indices = [data_list.index(sorted_features[0]), data_list.index(sorted_features[1]), data_list.index(sorted_features[2]), data_list.index(sorted_features[3]), data_list.index(sorted_features[4])]\n",
    "train_five = train_data[:, five_indices]\n",
    "test_five = test_data[:, five_indices]\n",
    "\n",
    "five_feature_names = [sorted_features[0], sorted_features[1], sorted_features[2], sorted_features[3], sorted_features[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on training data\n",
    "rf_five.fit(train_five, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on the training set\n",
    "accuracy_train_rf_five = rf_five.score(train_five, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of true labels: 0.17\n",
      "Accuracy: 0.8832239540607055\n",
      "Precision: 0.7701559020044544\n",
      "Recall: 0.42586206896551726\n",
      "F1-Score: 0.5484536082474227\n",
      "MCC: 0.5159945931490703\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set and calculate metrics\n",
    "predictions_rf_five, metrics_rf_five, accuracy_rf_five, precision_rf_five, recall_rf_five, f1_rf_five, mcc_rf_five = predict_with_model(rf_five, test_five, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable importances\n",
    "importances_rf_five, feature_importances_rf_five = calculate_feature_importances(rf_five, five_feature_names, output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E07W', 'E07CO2', 'E07Tair', 'E07ElL', 'Weekday Name_Saturday']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importances\n",
    "\n",
    "# adapting for each model\n",
    "importances = importances_rf_five\n",
    "features = five_feature_names\n",
    "\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "importances_percent = [element*100 for element in importances]\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances_percent, orientation = 'vertical', color='darkblue')\n",
    "# Tick Labels for x axis\n",
    "plt.xticks(x_values, features, rotation = 'vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Einfluss in %'); plt.xlabel('Merkmal'); plt.title('Einfluss der Merkmale auf die Vorhersage - '+e);\n",
    "#plt.ylabel('Importance in %'); plt.xlabel('Feature'); plt.title('Feature Importances - '+e);\n",
    "plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_feature_importances.pdf',bbox_inches='tight', dpi=100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual and predicted values\n",
    "plot_actual_predicted_values(test_data_vis, test_labels, predictions_rf_five)\n",
    "plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_actual_and_predicted_values.pdf',bbox_inches='tight', dpi=100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19804   516]\n",
      " [ 2331  1729]]\n"
     ]
    }
   ],
   "source": [
    "# *Confusion Matrix*\n",
    "\n",
    "print(confusion_matrix(test_labels, predictions_rf_five))\n",
    "# Plot confusion matrix\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "#titles_options = [(\"Konfusionsmatrix ohne Normalisierung\", None),\n",
    "#                     (\"Normalisierte Konfusionsmatrix\", 'true')]\n",
    "titles_options = [(\"Confusion matrix without normalization\", None),\n",
    "                     (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(rf_five, test_five, test_labels,\n",
    "                                    cmap=plt.cm.Blues,\n",
    "                                    normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "    plt.savefig('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_forecast_'+e+'_'+title+'.pdf',bbox_inches='tight', dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating csv file with results\n",
    "with open('Random_Forest_'+a+'_'+model_name+'_input_'+b+'_results.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Timestep','Accuracy - Training Set', 'Accuracy - Test Set','Precision', 'Recall','F1-Score', 'Matthews Correlation Coefficient'])\n",
    "    writer.writerow([e, accuracy_train_rf_five, accuracy_rf_five, precision_rf_five, recall_rf_five, f1_rf_five, mcc_rf_five])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20320"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(test_labels == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4060"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(test_labels == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
