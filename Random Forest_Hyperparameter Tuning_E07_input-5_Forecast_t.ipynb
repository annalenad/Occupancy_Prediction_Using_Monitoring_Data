{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning of a Random Forest Model for Occupancy Prediction in an Office Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process inspired by: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74 (accessed on 2021/01/03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Analytics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "## Plots\n",
    "\n",
    "# Import matplotlib and seaborn for plotting and use magic command for Jupyter Notebooks\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Set the style for plots\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rc(\"font\", size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "#sns.set(rc={'figure.figsize':(20, 10)})\n",
    "# Pydot is used for visualization\n",
    "import pydot\n",
    "\n",
    "\n",
    "## Machine Learning\n",
    "\n",
    "# Skicit-learn\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "# Import the model that is used - Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "# Import function to calculate accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "# Precision and recall\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "# Import autocorrelation function\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "# Import Matthews Correlation Coefficient\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "\n",
    "# CSV\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = room number\n",
    "a = 'E07'\n",
    "# b = number of lags as input\n",
    "b = '5'\n",
    "# c = number of last timestep to predict\n",
    "c = 0\n",
    "# t = timesteps for seperate plots\n",
    "#t = [6, 12, 18, 24, 30, 36]\n",
    "# d = number of timestep to predict\n",
    "d = 0\n",
    "# e = timestep in format 't+x' as string\n",
    "e = 't'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 1\n",
    "def predict_with_model(fitted_model, X_val, y_val, output=True):\n",
    "    '''\n",
    "    Function to make a prediction based on a trained model, returns metrics for classification\n",
    "    \n",
    "    Inputs: \n",
    "    fitted_model: On a training set fitted model to use for prediction \n",
    "    X_val (df): Dataframe with feature vectors of validation (or test) data\n",
    "    y_val (df): Dataframe with true labels of validation(or test) data\n",
    "    output (bool): if output should be printed or not, default is True\n",
    "   \n",
    "    Outputs:\n",
    "    y_pred (np.array): Prediction for feature vectors of validation (or test) data of the model\n",
    "    metrics_dict (dict): Dictionary with metrics for classification\n",
    "    accuracy (float): Accuracy of the prediction\n",
    "    precision (float): Precision of the prediction\n",
    "    recall (float): Recall of the prediction\n",
    "    f1 (float): F1-Score of the prediction\n",
    "    mcc (float): Matthews Correlation Coefficient of the prediction\n",
    "    '''  \n",
    "    \n",
    "    # Use the trained model to make predictions on the validation (or test) set\n",
    "    y_pred = fitted_model.predict(X_val)\n",
    "    \n",
    "    ## Metrics for classification\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    # Precision\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    # Recall\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    # F1-Score\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    # MCC\n",
    "    mcc = matthews_corrcoef(y_val, y_pred)\n",
    "    \n",
    "        \n",
    "    metrics_dict = {'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1,\n",
    "                    'mcc': mcc\n",
    "                   }\n",
    "    \n",
    "    if output:\n",
    "        print('Mean of true labels:', round(np.mean(y_val), 2))\n",
    "        print('Accuracy:', accuracy)\n",
    "        print('Precision:', precision)\n",
    "        print('Recall:', recall)\n",
    "        print('F1-Score:', f1)\n",
    "        print('MCC:', mcc)\n",
    "            \n",
    "    return y_pred, metrics_dict, accuracy, precision, recall, f1, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 2\n",
    "def cross_validation_timeseries(model, X_train, y_train, n_splits, output=True):\n",
    "    '''\n",
    "    Function to apply a cross validation to timeseries data based on a initialized model, returns metrics for classification\n",
    "    \n",
    "    Inputs: \n",
    "    model: a model initialized with the chosen hyperparameters\n",
    "    X_train (np.array): Numpy array with feature vectors of the training set (that is also used for validation)\n",
    "    y_train (np.array): Numpy array with labels of the training set (that is also used for validation)\n",
    "    n_splits (int): number of splits used in the cross-validation \n",
    "    output (bool): if output should be printed or not, default is True\n",
    "    \n",
    "    Outputs:\n",
    "    summary_cv_dict (dict): Dictionary with mean and standard deviation of the metrics for classification\n",
    "    '''\n",
    "    \n",
    "    # Define the way the data is split and the number of splits used for cross validation - no default value is set\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    \n",
    "    # Create lists to save results and calculate mean and standard deviation in the end over all iterations\n",
    "    acc_val_cv = []\n",
    "    precision_cv = []\n",
    "    recall_cv = []\n",
    "    f1_cv = []\n",
    "    mcc_cv = []\n",
    "    size = []\n",
    "    \n",
    "    for train_index, val_index in tscv.split(X_train):\n",
    "        cv_train, cv_val = X_train[train_index], X_train[val_index]\n",
    "        cv_train_labels, cv_val_labels = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        # Train model on the training data\n",
    "        model.fit(cv_train, cv_train_labels)\n",
    "        \n",
    "        # Make predictions on the validation set\n",
    "        y_pred, metrics_dict, accuracy, precision, recall, f1, mcc = predict_with_model(model, cv_val, cv_val_labels, output=False)\n",
    "        \n",
    "        # Save results to the lists\n",
    "        acc_val_cv.append(accuracy)\n",
    "        precision_cv.append(precision)\n",
    "        recall_cv.append(recall)\n",
    "        f1_cv.append(f1)\n",
    "        mcc_cv.append(mcc)\n",
    "        \n",
    "        # Check if Cross Validation worked properly\n",
    "        size.append((cv_train.shape, cv_val.shape))\n",
    "        print(\"Train:\", train_index, \"Validation\", val_index)\n",
    "    \n",
    "    # Calculate mean and standard deviation of the metrics to evaluate\n",
    "    acc_val_mean = np.mean(acc_val_cv)\n",
    "    acc_val_std = np.std(acc_val_cv, ddof=1)\n",
    "    precision_mean = np.mean(precision_cv)\n",
    "    precision_std = np.std(precision_cv, ddof=1)\n",
    "    recall_mean = np.mean(recall_cv)\n",
    "    recall_std = np.std(recall_cv, ddof=1)\n",
    "    f1_mean = np.mean(f1_cv)\n",
    "    f1_std = np.std(f1_cv, ddof=1)\n",
    "    mcc_mean = np.mean(mcc_cv)\n",
    "    mcc_std = np.std(mcc_cv, ddof=1)\n",
    "    \n",
    "    summary_cv_dict = {'accuracy_mean': acc_val_mean,\n",
    "                      'accuracy_std': acc_val_std,\n",
    "                      'precision_mean': precision_mean,\n",
    "                      'precision_std': precision_std,\n",
    "                      'recall_mean': recall_mean,\n",
    "                      'recall_std': recall_std,\n",
    "                      'f1_mean': f1_mean,\n",
    "                      'f1_std': f1_std,\n",
    "                      'mcc_mean': mcc_mean,\n",
    "                      'mcc_std': mcc_std}\n",
    "\n",
    "    if output:    \n",
    "        print(\"Acc_Val: {}\".format(acc_val_mean))\n",
    "        print(\"Acc_Val_Std: {}\".format(acc_val_std))\n",
    "        print(\"Precision: {}\".format(precision_mean))\n",
    "        print(\"Precision_Std: {}\".format(precision_std))\n",
    "        print(\"Recall: {}\".format(recall_mean))\n",
    "        print(\"Recall_Std: {}\".format(recall_std))\n",
    "        print(\"F1-Score: {}\".format(f1_mean))\n",
    "        print(\"F1-Score_Std: {}\".format(f1_std))\n",
    "        print(\"MCC: {}\".format(mcc_mean))\n",
    "        print(\"MCC_Std: {}\".format(mcc_std))\n",
    "        \n",
    "    return summary_cv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 3\n",
    "def evaluate_results_cv(results_cv, score):\n",
    "    '''\n",
    "    Function to find the best value of the chosen score to evaluate the best hyperparameters tested on the cross validation\n",
    "    \n",
    "    Inputs:\n",
    "    results_cv (df): Dataframe with results of the cross validations\n",
    "    score (str): metric that should be used to evaluate the results\n",
    "            possible options are: {'accuracy_mean', 'accuracy_std',\n",
    "                                    'precision_mean', 'precision_std',\n",
    "                                    'recall_mean', 'recall_std',\n",
    "                                    'f1_mean', 'f1_std',\n",
    "                                    'mcc_mean', 'mcc_std'}\n",
    "    \n",
    "    Outputs:\n",
    "    max_value (float): maximum score reached of the chosen metric\n",
    "    idx_max_value (int): index of the corresponding cross validation in results_cv\n",
    "    '''\n",
    "    \n",
    "    max_value = results_cv[score].max()\n",
    "    idx_max_value = results_cv[score].idxmax()\n",
    "    \n",
    "    print('The best ' + score + ' is reached at cross validation with index ' + str((idx_max_value)) + ' with ' + str(max_value)+'.')\n",
    "    \n",
    "    return max_value, idx_max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 4 \n",
    "def create_random_hyperparameter_rf(param_grid, n_comb):\n",
    "    '''\n",
    "    Function to create a random set of hyperparameter as a dict out of a given parameter grid for a random forest\n",
    "    \n",
    "    Inputs:\n",
    "    param_grid (dict): parameter grid to choose random values from\n",
    "                        needs to contain values for:\n",
    "                        {n_estimators, max_features, max_depth, min_samples_split, min_samples_leaf, bootstrap, random_state}\n",
    "    n_comb (int): number of how many combinations should be generated (models to try)\n",
    "    \n",
    "    Outputs:\n",
    "    hyperparameter (list): list containing the different combinations of hyperparameter as dicts\n",
    "    '''\n",
    "\n",
    "    hyperparameter = [{'n_estimators': random.choice(param_grid['n_estimators']),\n",
    "                   'max_features': random.choice(param_grid['max_features']),    \n",
    "                   'max_depth': random.choice(param_grid['max_depth']),\n",
    "                   'min_samples_split': random.choice(param_grid['min_samples_split']),\n",
    "                   'min_samples_leaf': random.choice(param_grid['min_samples_leaf']),\n",
    "                   'bootstrap': random.choice(param_grid['bootstrap']),\n",
    "                    'random_state': random.choice(param_grid['random_state'])} for i in range (0, n_comb)]\n",
    "    \n",
    "    return hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 5\n",
    "\n",
    "def hyperparameter_tuning_timeseries_cv_rf(X_train, y_train, param_grid, score, n_splits, n_comb):\n",
    "    '''\n",
    "    Function for estimating the best hyperparameter of a random forest based on random combinations of hyperparameters \n",
    "    validated using cross-validation with time series split\n",
    "    \n",
    "    Inputs:\n",
    "    X_train (np.array): Numpy array with feature vectors of the training set (that is also used for validation)\n",
    "    y_train (np.array): Numpy array with labels of the training set (that is also used for validation)\n",
    "    param_grid (dict): grid of different values for the hyperparameter to choose randomly from\n",
    "    score (str): metric that should be used to evaluate to results\n",
    "            possible options are: {'accuracy_mean', 'accuracy_std',\n",
    "                                    'precision_mean', 'precision_std',\n",
    "                                    'recall_mean', 'recall_std',\n",
    "                                    'f1_mean', 'f1_std',\n",
    "                                    'mcc_mean', 'mcc_std'} \n",
    "    n_splits (int): number of splits used in the cross-validation\n",
    "    n_comb (int): number of how many combinations of hyperparameter should be generated (models to try)\n",
    "    \n",
    "    Outputs:\n",
    "    results (df): Dataframe that contains the calculated metrics and the different hyperparameter\n",
    "    '''\n",
    "    \n",
    "    # create n_comb different combinations of hyperparameter out of the param_grid\n",
    "    hyperparameter_rf = create_random_hyperparameter_rf(param_grid_rf, n_comb)\n",
    "\n",
    "    # create base model\n",
    "    rf = RandomForestClassifier()\n",
    "    \n",
    "    for index, hyperparameters in enumerate(hyperparameter_rf):\n",
    "        \n",
    "        # Instantiate model\n",
    "        rf_random = rf.set_params(**hyperparameters)\n",
    "        \n",
    "        # time series split cross validation \n",
    "        cv = cross_validation_timeseries(rf_random, X_train, y_train, n_splits=n_splits, output=False)\n",
    "        \n",
    "        # Create dataframe with results\n",
    "        if index == 0:\n",
    "            df1 = pd.DataFrame(hyperparameters, index=['0'])\n",
    "            df2 = pd.DataFrame(cv, index=['0'])\n",
    "            results = pd.concat([df1, df2], axis=1)\n",
    "        else:\n",
    "            df1 = pd.DataFrame(hyperparameters, index=['0'])\n",
    "            df2 = pd.DataFrame(cv, index=['0'])\n",
    "            df3 = pd.concat([df1, df2], axis=1)\n",
    "            results = results.append(df3, ignore_index=True)\n",
    "        \n",
    "    # Evaluate results of cross validation\n",
    "    max_value, idx_max_value = evaluate_results_cv(results, score)\n",
    "    \n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data and set index\n",
    "raw_data = pd.read_csv(\"\\Pre-Processing\\data_E07_input_5_output_144.txt\", parse_dates=True)\n",
    "data = raw_data.copy()\n",
    "data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "data = data.set_index('DateTime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns for Second\n",
    "data = data.drop('Second_0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns of future timestamps that should not be used as input for this model\n",
    "if d==0:\n",
    "    for i in range(1,145):\n",
    "        v = 't+'+str(i)\n",
    "        data = data.drop(v, axis = 1)\n",
    "else:\n",
    "    for i in range(d+1,145):\n",
    "        v = 't+'+str(i)\n",
    "        data = data.drop(v, axis = 1)\n",
    "\n",
    "    for i in range(1, d):\n",
    "        v = 't+'+str(i)\n",
    "        data = data.drop(v, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns with year, month, day and weekday name at the end of the dataset for later use of visualization \n",
    "data['Year'] = data.index.year\n",
    "data['Month'] = data.index.month\n",
    "data['Day'] = data.index.day\n",
    "data['Weekday Name'] = data.index.day_name()\n",
    "data['Hour'] = data.index.hour\n",
    "data['Minute'] = data.index.minute\n",
    "data['Second'] = data.index.second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy to convert to arrays\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(data[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the labels from the data\n",
    "# axis 1 refers to the columns\n",
    "data = data.drop(e, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data names for later use\n",
    "data_list = list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save copy before transforming to numpy array\n",
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the one hot encoded data\n",
    "# lags should not be used in this model\n",
    "feature_names = [i for i in data_list if i not in ['t-5', 't-4', 't-3', 't-2', 't-1',\n",
    "                                                    'Year', 'Month','Day','Hour','Minute','Second','Weekday Name']]\n",
    "indices = [data_list.index(feature_names[x]) for x in range(0,len(feature_names))]\n",
    "data = data[:, indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets using scikit-learn \n",
    "# 25 % so that approximately the last 6 months are covered\n",
    "# shuffle = False because of time series data\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size = 0.25, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (73137, 86)\n",
      "Training Labels Shape: (73137,)\n",
      "Testing Data Shape: (24380, 86)\n",
      "Testing Labels Shape: (24380,)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes of data sets\n",
    "print('Training Data Shape:', train_data.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Data Shape:', test_data.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Create different values for the different hyperparameter to use for the parameter grid\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 5)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['auto']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True]\n",
    "# # random_state\n",
    "# random_state = [42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create different values for the different hyperparameter to use for the parameter grid\n",
    "# Number of trees in random forest\n",
    "n_estimators = [100, 500, 775]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto']\n",
    "# Maximum number of levels in tree\n",
    "#max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "#max_depth.append(None)\n",
    "max_depth = [40, 50, 60, 70]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 4, 5, 6, 8]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "# random_state\n",
    "random_state = [42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "param_grid_rf = {'n_estimators': n_estimators,\n",
    "                 'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "                'random_state': random_state}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splits = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [   0    1    2 ... 8126 8127 8128] Validation [ 8129  8130  8131 ... 16252 16253 16254]\n",
      "Train: [    0     1     2 ... 16252 16253 16254] Validation [16255 16256 16257 ... 24378 24379 24380]\n",
      "Train: [    0     1     2 ... 24378 24379 24380] Validation [24381 24382 24383 ... 32504 32505 32506]\n",
      "Train: [    0     1     2 ... 32504 32505 32506] Validation [32507 32508 32509 ... 40630 40631 40632]\n",
      "Train: [    0     1     2 ... 40630 40631 40632] Validation [40633 40634 40635 ... 48756 48757 48758]\n",
      "Train: [    0     1     2 ... 48756 48757 48758] Validation [48759 48760 48761 ... 56882 56883 56884]\n",
      "Train: [    0     1     2 ... 56882 56883 56884] Validation [56885 56886 56887 ... 65008 65009 65010]\n",
      "Train: [    0     1     2 ... 65008 65009 65010] Validation [65011 65012 65013 ... 73134 73135 73136]\n",
      "Train: [   0    1    2 ... 8126 8127 8128] Validation [ 8129  8130  8131 ... 16252 16253 16254]\n",
      "Train: [    0     1     2 ... 16252 16253 16254] Validation [16255 16256 16257 ... 24378 24379 24380]\n",
      "Train: [    0     1     2 ... 24378 24379 24380] Validation [24381 24382 24383 ... 32504 32505 32506]\n",
      "Train: [    0     1     2 ... 32504 32505 32506] Validation [32507 32508 32509 ... 40630 40631 40632]\n",
      "Train: [    0     1     2 ... 40630 40631 40632] Validation [40633 40634 40635 ... 48756 48757 48758]\n",
      "Train: [    0     1     2 ... 48756 48757 48758] Validation [48759 48760 48761 ... 56882 56883 56884]\n",
      "Train: [    0     1     2 ... 56882 56883 56884] Validation [56885 56886 56887 ... 65008 65009 65010]\n",
      "Train: [    0     1     2 ... 65008 65009 65010] Validation [65011 65012 65013 ... 73134 73135 73136]\n",
      "Train: [   0    1    2 ... 8126 8127 8128] Validation [ 8129  8130  8131 ... 16252 16253 16254]\n",
      "Train: [    0     1     2 ... 16252 16253 16254] Validation [16255 16256 16257 ... 24378 24379 24380]\n",
      "Train: [    0     1     2 ... 24378 24379 24380] Validation [24381 24382 24383 ... 32504 32505 32506]\n",
      "Train: [    0     1     2 ... 32504 32505 32506] Validation [32507 32508 32509 ... 40630 40631 40632]\n",
      "Train: [    0     1     2 ... 40630 40631 40632] Validation [40633 40634 40635 ... 48756 48757 48758]\n",
      "Train: [    0     1     2 ... 48756 48757 48758] Validation [48759 48760 48761 ... 56882 56883 56884]\n",
      "Train: [    0     1     2 ... 56882 56883 56884] Validation [56885 56886 56887 ... 65008 65009 65010]\n",
      "Train: [    0     1     2 ... 65008 65009 65010] Validation [65011 65012 65013 ... 73134 73135 73136]\n",
      "Train: [   0    1    2 ... 8126 8127 8128] Validation [ 8129  8130  8131 ... 16252 16253 16254]\n",
      "Train: [    0     1     2 ... 16252 16253 16254] Validation [16255 16256 16257 ... 24378 24379 24380]\n",
      "Train: [    0     1     2 ... 24378 24379 24380] Validation [24381 24382 24383 ... 32504 32505 32506]\n",
      "Train: [    0     1     2 ... 32504 32505 32506] Validation [32507 32508 32509 ... 40630 40631 40632]\n",
      "Train: [    0     1     2 ... 40630 40631 40632] Validation [40633 40634 40635 ... 48756 48757 48758]\n",
      "Train: [    0     1     2 ... 48756 48757 48758] Validation [48759 48760 48761 ... 56882 56883 56884]\n",
      "Train: [    0     1     2 ... 56882 56883 56884] Validation [56885 56886 56887 ... 65008 65009 65010]\n",
      "Train: [    0     1     2 ... 65008 65009 65010] Validation [65011 65012 65013 ... 73134 73135 73136]\n",
      "Train: [   0    1    2 ... 8126 8127 8128] Validation [ 8129  8130  8131 ... 16252 16253 16254]\n",
      "Train: [    0     1     2 ... 16252 16253 16254] Validation [16255 16256 16257 ... 24378 24379 24380]\n",
      "Train: [    0     1     2 ... 24378 24379 24380] Validation [24381 24382 24383 ... 32504 32505 32506]\n",
      "Train: [    0     1     2 ... 32504 32505 32506] Validation [32507 32508 32509 ... 40630 40631 40632]\n",
      "Train: [    0     1     2 ... 40630 40631 40632] Validation [40633 40634 40635 ... 48756 48757 48758]\n",
      "Train: [    0     1     2 ... 48756 48757 48758] Validation [48759 48760 48761 ... 56882 56883 56884]\n",
      "Train: [    0     1     2 ... 56882 56883 56884] Validation [56885 56886 56887 ... 65008 65009 65010]\n",
      "Train: [    0     1     2 ... 65008 65009 65010] Validation [65011 65012 65013 ... 73134 73135 73136]\n",
      "The best mcc_mean is reached at cross validation with index 1 with 0.5825678486996339.\n"
     ]
    }
   ],
   "source": [
    "results_hyp_splits_8_comb_5_t = hyperparameter_tuning_timeseries_cv_rf(train_data, train_labels, param_grid_rf, 'mcc_mean', n_splits=8, n_comb=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>random_state</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>mcc_mean</th>\n",
       "      <th>mcc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>0.866970</td>\n",
       "      <td>0.042845</td>\n",
       "      <td>0.615569</td>\n",
       "      <td>0.095375</td>\n",
       "      <td>0.697681</td>\n",
       "      <td>0.225784</td>\n",
       "      <td>0.631158</td>\n",
       "      <td>0.131999</td>\n",
       "      <td>0.570135</td>\n",
       "      <td>0.145203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>775</td>\n",
       "      <td>auto</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>0.870554</td>\n",
       "      <td>0.046214</td>\n",
       "      <td>0.627094</td>\n",
       "      <td>0.099263</td>\n",
       "      <td>0.706856</td>\n",
       "      <td>0.232326</td>\n",
       "      <td>0.640086</td>\n",
       "      <td>0.142171</td>\n",
       "      <td>0.582568</td>\n",
       "      <td>0.151947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>auto</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>0.868832</td>\n",
       "      <td>0.045395</td>\n",
       "      <td>0.620606</td>\n",
       "      <td>0.098183</td>\n",
       "      <td>0.713852</td>\n",
       "      <td>0.231442</td>\n",
       "      <td>0.639999</td>\n",
       "      <td>0.135057</td>\n",
       "      <td>0.581622</td>\n",
       "      <td>0.148141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>0.867462</td>\n",
       "      <td>0.041734</td>\n",
       "      <td>0.617662</td>\n",
       "      <td>0.092970</td>\n",
       "      <td>0.697421</td>\n",
       "      <td>0.228721</td>\n",
       "      <td>0.631250</td>\n",
       "      <td>0.131289</td>\n",
       "      <td>0.571207</td>\n",
       "      <td>0.143298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>775</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>0.870431</td>\n",
       "      <td>0.046209</td>\n",
       "      <td>0.626067</td>\n",
       "      <td>0.099314</td>\n",
       "      <td>0.707295</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.640982</td>\n",
       "      <td>0.138948</td>\n",
       "      <td>0.582478</td>\n",
       "      <td>0.150720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators max_features  max_depth  min_samples_split  min_samples_leaf  \\\n",
       "0           100         auto         50                  5                 1   \n",
       "1           775         auto         40                  6                 2   \n",
       "2           500         auto         70                  8                 1   \n",
       "3           100         auto         60                  5                 1   \n",
       "4           775         auto         50                  6                 2   \n",
       "\n",
       "   bootstrap  random_state  accuracy_mean  accuracy_std  precision_mean  \\\n",
       "0       True            42       0.866970      0.042845        0.615569   \n",
       "1       True            42       0.870554      0.046214        0.627094   \n",
       "2       True            42       0.868832      0.045395        0.620606   \n",
       "3       True            42       0.867462      0.041734        0.617662   \n",
       "4       True            42       0.870431      0.046209        0.626067   \n",
       "\n",
       "   precision_std  recall_mean  recall_std   f1_mean    f1_std  mcc_mean  \\\n",
       "0       0.095375     0.697681    0.225784  0.631158  0.131999  0.570135   \n",
       "1       0.099263     0.706856    0.232326  0.640086  0.142171  0.582568   \n",
       "2       0.098183     0.713852    0.231442  0.639999  0.135057  0.581622   \n",
       "3       0.092970     0.697421    0.228721  0.631250  0.131289  0.571207   \n",
       "4       0.099314     0.707295    0.228619  0.640982  0.138948  0.582478   \n",
       "\n",
       "    mcc_std  \n",
       "0  0.145203  \n",
       "1  0.151947  \n",
       "2  0.148141  \n",
       "3  0.143298  \n",
       "4  0.150720  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_hyp_splits_8_comb_5_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_hyp_splits_8_comb_5_t.to_csv('results_hyp_splits_8_comb_5_t.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_param = results_hyp_splits_8_comb_5_t[['n_estimators', 'max_features', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'bootstrap', 'random_state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_metrics = results_hyp_splits_8_comb_5_t[['accuracy_mean', 'accuracy_std' ,'precision_mean', 'precision_std', 'recall_mean', 'recall_std', 'f1_mean', 'f1_std', \n",
    "                   'mcc_mean', 'mcc_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_param['index'] = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>random_state</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>775</td>\n",
       "      <td>auto</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>auto</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>775</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_estimators max_features  max_depth  min_samples_split  \\\n",
       "index                                                            \n",
       "1               100         auto         50                  5   \n",
       "2               775         auto         40                  6   \n",
       "3               500         auto         70                  8   \n",
       "4               100         auto         60                  5   \n",
       "5               775         auto         50                  6   \n",
       "\n",
       "       min_samples_leaf  bootstrap  random_state  index  \n",
       "index                                                    \n",
       "1                     1       True            42      1  \n",
       "2                     2       True            42      2  \n",
       "3                     1       True            42      3  \n",
       "4                     1       True            42      4  \n",
       "5                     2       True            42      5  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>mcc_mean</th>\n",
       "      <th>mcc_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.866970</td>\n",
       "      <td>0.042845</td>\n",
       "      <td>0.615569</td>\n",
       "      <td>0.095375</td>\n",
       "      <td>0.697681</td>\n",
       "      <td>0.225784</td>\n",
       "      <td>0.631158</td>\n",
       "      <td>0.131999</td>\n",
       "      <td>0.570135</td>\n",
       "      <td>0.145203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.870554</td>\n",
       "      <td>0.046214</td>\n",
       "      <td>0.627094</td>\n",
       "      <td>0.099263</td>\n",
       "      <td>0.706856</td>\n",
       "      <td>0.232326</td>\n",
       "      <td>0.640086</td>\n",
       "      <td>0.142171</td>\n",
       "      <td>0.582568</td>\n",
       "      <td>0.151947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.868832</td>\n",
       "      <td>0.045395</td>\n",
       "      <td>0.620606</td>\n",
       "      <td>0.098183</td>\n",
       "      <td>0.713852</td>\n",
       "      <td>0.231442</td>\n",
       "      <td>0.639999</td>\n",
       "      <td>0.135057</td>\n",
       "      <td>0.581622</td>\n",
       "      <td>0.148141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.867462</td>\n",
       "      <td>0.041734</td>\n",
       "      <td>0.617662</td>\n",
       "      <td>0.092970</td>\n",
       "      <td>0.697421</td>\n",
       "      <td>0.228721</td>\n",
       "      <td>0.631250</td>\n",
       "      <td>0.131289</td>\n",
       "      <td>0.571207</td>\n",
       "      <td>0.143298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.870431</td>\n",
       "      <td>0.046209</td>\n",
       "      <td>0.626067</td>\n",
       "      <td>0.099314</td>\n",
       "      <td>0.707295</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.640982</td>\n",
       "      <td>0.138948</td>\n",
       "      <td>0.582478</td>\n",
       "      <td>0.150720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy_mean  accuracy_std  precision_mean  precision_std  \\\n",
       "index                                                               \n",
       "1           0.866970      0.042845        0.615569       0.095375   \n",
       "2           0.870554      0.046214        0.627094       0.099263   \n",
       "3           0.868832      0.045395        0.620606       0.098183   \n",
       "4           0.867462      0.041734        0.617662       0.092970   \n",
       "5           0.870431      0.046209        0.626067       0.099314   \n",
       "\n",
       "       recall_mean  recall_std   f1_mean    f1_std  mcc_mean   mcc_std  \n",
       "index                                                                   \n",
       "1         0.697681    0.225784  0.631158  0.131999  0.570135  0.145203  \n",
       "2         0.706856    0.232326  0.640086  0.142171  0.582568  0.151947  \n",
       "3         0.713852    0.231442  0.639999  0.135057  0.581622  0.148141  \n",
       "4         0.697421    0.228721  0.631250  0.131289  0.571207  0.143298  \n",
       "5         0.707295    0.228619  0.640982  0.138948  0.582478  0.150720  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_metrics.set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## default setting in CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try default with cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "param_grid_rf = {'n_estimators': [100],\n",
    "                 'max_features': ['auto'],\n",
    "               'max_depth': [None],\n",
    "               'min_samples_split': [2],\n",
    "               'min_samples_leaf': [1],\n",
    "               'bootstrap': bootstrap,\n",
    "                'random_state': random_state}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [   0    1    2 ... 8126 8127 8128] Validation [ 8129  8130  8131 ... 16252 16253 16254]\n",
      "Train: [    0     1     2 ... 16252 16253 16254] Validation [16255 16256 16257 ... 24378 24379 24380]\n",
      "Train: [    0     1     2 ... 24378 24379 24380] Validation [24381 24382 24383 ... 32504 32505 32506]\n",
      "Train: [    0     1     2 ... 32504 32505 32506] Validation [32507 32508 32509 ... 40630 40631 40632]\n",
      "Train: [    0     1     2 ... 40630 40631 40632] Validation [40633 40634 40635 ... 48756 48757 48758]\n",
      "Train: [    0     1     2 ... 48756 48757 48758] Validation [48759 48760 48761 ... 56882 56883 56884]\n",
      "Train: [    0     1     2 ... 56882 56883 56884] Validation [56885 56886 56887 ... 65008 65009 65010]\n",
      "Train: [    0     1     2 ... 65008 65009 65010] Validation [65011 65012 65013 ... 73134 73135 73136]\n",
      "The best mcc_mean is reached at cross validation with index 0 with 0.5795393327075484.\n"
     ]
    }
   ],
   "source": [
    "# try default setting in CV with 8 splits\n",
    "results_hyp_splits_8_comb_1_t_def = hyperparameter_tuning_timeseries_cv_rf(train_data, train_labels, param_grid_rf, 'mcc_mean', n_splits=8, n_comb=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_hyp_splits_8_comb_1_t_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_hyp_splits_8_comb_1_t_def.drop(['n_estimators', 'max_features', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'bootstrap', 'random_state'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcc 0.4576 in CV\n",
    "best_random = RandomForestClassifier(n_estimators=775, max_depth=60, min_samples_split=2, min_samples_leaf=1, random_state=42)\n",
    "best_random.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_with_model(best_random, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "base_model.fit(train_data, train_labels)\n",
    "base_accuracy = base_model.score(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.score(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_with_model(base_model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = RandomForestClassifier(n_estimators=233, max_features='sqrt', max_depth=76, min_samples_split=2, min_samples_leaf=2, bootstrap=True)\n",
    "best_random.fit(train_data, train_labels)\n",
    "random_accuracy = best_random.score(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
